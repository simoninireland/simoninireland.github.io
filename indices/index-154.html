<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Simon Dobson (old posts, page 154)</title>
<style>
	@font-face {
	    font-family: "libretto-icons";
	    src:url(../assets/fonts/libretto-icons.eot);
	    src:url(../assets/fonts/libretto-icons.eot#iefix) format("embedded-opentype"),
	    url(../assets/fonts/libretto-icons.woff) format("woff"),
	    url(../assets/fonts/libretto-icons.ttf) format("truetype"),
	    url(../assets/fonts/libretto-icons.svg#libretto-icons) format("svg");
	    font-weight: normal;
	    font-style: normal;
	}
    </style>
<link rel="icon" href="../images/favicon.png" sizes="16x16">
<link rel="alternate" type="application/rss+xml" href="../rss.xml">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Sans+Mono|Libre+Baskerville|Montserrat|Playfair+Display|Tangerine">
<link rel="stylesheet" href="../assets/css/libretto_styles.css">
<link rel="stylesheet" href="../assets/css/baguetteBox.min.css">
<link rel="stylesheet" href="../assets/css/code.css">
<link rel="stylesheet" href="../assets/css/nikola_rst.css">
<link rel="stylesheet" href="../assets/css/nikola_ipython.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
</head>
<body>
    <!-- Navigation bar -->
    <header class="nav-bar"><div class="site-branding">
	    <h1 class="site-title">
		<a href="https://simondobson.org/" title="Simon Dobson" rel="home">Simon&nbsp;Dobson</a>
	    </h1>
	</div>
	<nav class="site-navigation" role="navigation"><div class="menu-toggle">
		<span class="mobile-site-title">Simon Dobson</span>
	    </div>
	    <ul class="menu">
<li><a href="../index.html">Home</a></li>
		    <li><a href="../personal/">About&nbsp;me</a></li>
		    <li><a href="../research/">Research</a></li>
		    <li><a href="../development/projects/">Software</a></li>
		    <li><a href="../writing/">Writing</a></li>
		    <li><a href="../personal/contact/">Contact</a></li>
		<li>
<a href="../rss.xml"><i class="fa fa-rss"></i></a>
	    </li>
</ul></nav></header><div class="site-content">
	    <article class="format-standard libretto-long-form"><div class="title-block post-format-icon-pin">
		    <div class="entry-meta">
			<span class="posted-on">
			    Posted on <a href="../goodreads/korea-a-new-history-of-south-and-north/" rel="bookmark">Sunday 9 March, 2025</a>
			</span>
		    </div>
		    <h1><a href="../goodreads/korea-a-new-history-of-south-and-north/">Korea: A New History of South and&nbsp;North</a></h1>
		</div>
		<div class="entry-content">
			<div>
    <div>
      <img src="https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1682203389l/62834771._SX98_.jpg" style="float: left; margin-right: 10px"><h2>
	Victor D. Cha&nbsp;(2023)
      </h2>
    </div>
    <p>
      The modern history of a nation that&#8217;s been to some extent marginalised by wider geopolitics. It begins with domination by Japan in the late 19th century, which continued until the end of the Second World War – only to be replaced by domination through &#8220;trusteeship&#8221; by the <span class="caps">US</span> and others, which itself was a direct precursor to the partition of the nation, a vicious war, and a long and convoluted evolution of two very different political and economic outcomes.<br><br>There are times when it feels a little superficial: the Korean War gets only a few pages. But that&#8217;s a consequence of the breadth of coverage, and especially the time spent analysing the politics as they evolve through repression (in the North) and authoritarianism becoming dictatorship and finally vibrant and raucous democracy (in the South).<br><br>The fact that both authors are Korea specialists (and in one case ethnically Korean) certainly helps. They have seen close-up the evolution of both Koreas&#8217; places in the world, and their personal observations and anecdotes bring the story alive without being distracting.<br><br>The last chapter is a detailed analysis of when and whether any re-unification of the pennisula will happen. It&#8217;s a balanced and well-informed view, albeit one that&#8217;s too sanguine with respect to the expectation of continued <span class="caps">US</span> support and engagement: the recent (as I write) events in Ukraine don&#8217;t give confidence in whether the <span class="caps">US</span> would act as an honest broker in any crisis. But it remains a clear and well-reasoned (if largely non-committal) analysis of where Krean history may go&nbsp;next.
      </p>
<p>
	4/5.
	  Finished Sunday 9 March,&nbsp;2025.
	</p>
<p>
	  (Originally published on <a href="https://www.goodreads.com/review/show/7034830867?utm_medium=api&amp;utm_source=rss">Goodreads</a>.)
  </p>
</div>
		</div>
	    </article>
</div>
	<div class="site-content">
	    <article class="format-standard libretto-long-form"><div class="title-block post-format-icon-pin">
		    <div class="entry-meta">
			<span class="posted-on">
			    Posted on <a href="../goodreads/doppelganger-a-trip-into-the-mirror-world/" rel="bookmark">Sunday 2 March, 2025</a>
			</span>
		    </div>
		    <h1><a href="../goodreads/doppelganger-a-trip-into-the-mirror-world/">Doppelganger: A Trip into the Mirror&nbsp;World</a></h1>
		</div>
		<div class="entry-content">
			<div>
    <div>
      <img src="https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1689105362l/138505710._SX98_.jpg" style="float: left; margin-right: 10px"><h2>
	Naomi Klein&nbsp;(2023)
      </h2>
    </div>
    <p>
      What does it mean for someone to have a double? That is the broad premise of this book, and its a lot broader than it first appears.<br><br>Klein&#8217;s doppelganger is another author, Naomi Wolf. Both began as liberal and feminist darlings, before &#8220;Other Naomi&#8221; (Wolf) became a proponent of various consipracy theories and hanging out with right-wing influencers. The two Naomis starte being confused with each other within social media, to the estent that Klein almost starts to lose her own sense of identity and becomes increasingly obsessed with tracking the confusion. (I was darkly amused to check Wolf out on <a>Wikipedia</a> and find that the page starts &#8220;Not to be confused with Naomi Klein&#8221; – and <i>vice versa</i> for Klein&#8217;s entry.)<br><br>There&#8217;s a certain feeling of narcissism in the account. Maybe Klein is affected so much because she and Wolf both have such curated on-line personalities, so that when Klein&#8217;s is intruded upon it feels like a personal attack. Would someone with less commitment to media be so affected? – well, I have to say I hope I never personally find out, because it comes across as a very destabilising experience.<br><br>Klein does take a broader view of the pheonomenon of &#8220;doubling&#8221;, which at one level feels unnecessary ad extraneous to this book but that I found quite fascinating in its own right: the idea that doubles appear in lots of circumstances for those with (and even without) a life in the public eye. For an author it&#8217;s natural to be worried about how the &#8220;double&#8221; that is one&#8217;s written work is interpreted and re-interpreted after it&#8217;s been published, without your control, and how this spills-back on to how people interpret everything you write from then on. Some of the examples feel a little contrived, others quite plausible.<br><br>So this book is both a personal memoir and a deeper exploration of a person&#8217;s relationship to their own work and life. Both sides are valuable and well worth&nbsp;reading.
      </p>
<p>
	4/5.
	  Finished Sunday 2 March,&nbsp;2025.
	</p>
<p>
	  (Originally published on <a href="https://www.goodreads.com/review/show/7247452978?utm_medium=api&amp;utm_source=rss">Goodreads</a>.)
  </p>
</div>
		</div>
	    </article>
</div>
	<div class="site-content">
	    <article class="format-standard libretto-long-form"><div class="title-block post-format-icon-pin">
		    <div class="entry-meta">
			<span class="posted-on">
			    Posted on <a href="../2025/01/31/tutorial-on-good-lisp-programming-style/" rel="bookmark">Friday 31 January, 2025</a>
			</span>
		    </div>
		    <h1><a href="../2025/01/31/tutorial-on-good-lisp-programming-style/">Tutorial on good Lisp programming&nbsp;style</a></h1>
		</div>
		<div class="entry-content">
			<div id="outline-container-org5e8f4b3" class="outline-2">
<h2 id="org5e8f4b3">Tutorial on good Lisp programming&nbsp;style</h2>
<div class="outline-text-2" id="text-org5e8f4b3">
<p>
<a href="https://www.cs.umd.edu/%7Enau/cmsc421/norvig-lisp-style.pdf">https://www.cs.umd.edu/%7Enau/cmsc421/norvig-lisp-style.pdf</a>
</p>

<p>
<i>Expression + Understanding =&nbsp;Communication</i>
</p>

<p>
A great discussion of <i>style</i>, perhaps the most elusive programming
skill. Illustrated across all the levels of abstraction that one
finds in Lisp: of data, functions, control, and syntax (the last
being essentially unique to Lisp macros). The discussion of
control abstraction deals extensively with catch/throw and other
primitives in the condition system that are dealt with at greater
length in <a href="/2024/03/06/the-common-lisp-condition-system/">The Common Lisp condition system</a>.
</p>

<p>
The extended example (starting on page 71) of how to simplify
logical expressions is amazingly clear, and really shows the
progression from simple functions to embedded languages targeting
specific tasks and making them easy to describe and extend to new
applications: something that lies at the heart of the Lisp&nbsp;experience.
</p>

<p>
Much of the advice is actually language-agnostic, even though the
concrete examples are in Lisp. Norvig, of course, is the author of
<a href="/2024/03/07/paradigms-of-artificial-intelligence-programming-case-studies-in-common-lisp/">Paradigms of artificial intelligence programming</a>, and has made
enormous contributions to the theory and practice of&nbsp;Lisp.
</p>
</div>
</div>
		</div>
	    </article>
</div>
	<div class="site-content">
	    <article class="format-standard libretto-long-form"><div class="title-block post-format-icon-pin">
		    <div class="entry-meta">
			<span class="posted-on">
			    Posted on <a href="../2025/01/31/lisp-style-and-design/" rel="bookmark">Friday 31 January, 2025</a>
			</span>
		    </div>
		    <h1><a href="../2025/01/31/lisp-style-and-design/">Lisp: Style and&nbsp;design</a></h1>
		</div>
		<div class="entry-content">
			<div id="outline-container-org07a794e" class="outline-2">
<h2 id="org07a794e">Lisp: Style and&nbsp;design</h2>
<div class="outline-text-2" id="text-org07a794e">
<p class="floater">
<img src="../attachments/da/4751c9-60cc-4acc-bfd3-ad7d50aa536a/lisp-style-design.jpg" alt="nil"></p>

<p>
Molly Miller and Eric Benson. <i>Lisp: Style and Design</i>. Digital Press.
<span class="caps">ISBN</span> 978-0135384220.&nbsp;1990.
</p>

<p>
A book that would serve as a primer for someone tackling a
significant piece of programming for the first&nbsp;time.
</p>

<p>
The style is a bit stiff and occasionally slightly patronising,
definitely positioned as being from senior to junior programmers.
The depth of the material is variable: I found the treatment of
macros quite superficial, not helped by the examples generating
questionable code. It also places relatively little emphasis on
<span class="caps">CLOS</span> and generic functions, which would get more space in a more
modern&nbsp;treatment..
</p>

<p>
The best chapters are those on debugging and (especially)
performance engineering, which dig into the interactive tools
generally available within Lisp and give a good end-to-end
description of the use&nbsp;of <code>declare</code> forms to aid compiler&nbsp;optimisations.
</p>

<p>
But again the book&#8217;s age shows. It predates the obsessive
relationship that many modern programmers have with unit testing
and test automation, treating testing as an interactive activity
alongside debugging rather than as a core and permanent part of
program development and&nbsp;maintenance.
</p>
</div>
</div>
		</div>
	    </article>
</div>
	<div class="site-content">
	    <article class="format-standard libretto-long-form"><div class="title-block post-format-icon-pin">
		    <div class="entry-meta">
			<span class="posted-on">
			    Posted on <a href="../goodreads/human-compatible-artificial-intelligence-and-the-problem-of-control/" rel="bookmark">Thursday 16 January, 2025</a>
			</span>
		    </div>
		    <h1><a href="../goodreads/human-compatible-artificial-intelligence-and-the-problem-of-control/">Human Compatible: Artificial Intelligence and the Problem of&nbsp;Control</a></h1>
		</div>
		<div class="entry-content">
			<div>
    <div>
      <img src="https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1561637199l/44767248._SX98_.jpg" style="float: left; margin-right: 10px"><h2>
	Stuart Russell&nbsp;(2019)
      </h2>
    </div>
    <p>
      A book that tries to address the emergence and implications of artificial intelligence.<br><br>(I should preface what I&#8217;m going to say by noting Brand&#8217;s enormous contributions to <span class="caps">AI</span> research and teaching. He knows massively more about these systems than I do.)<br><br>Computer scientists often avoid the term &#8220;<span class="caps">AI</span>&#8221; because it&#8217;s so broad and encompasses a huge range of approaches, from constraint-solving and pattern-matching to speech recognition and the sorts of &#8220;chatbot&#8221; technology that is the common face of modern <span class="caps">AI</span> – technically referred to as Large Language Models or LLMs, that have been trained on text scraped from the internet and can perform impressive feats of conversation.<br><br>There&#8217;s a problem when discussing <span class="caps">AI</span> that you have to be very careful about, and that&#8217;s the tendency to anthropomorphise. It&#8217;s almost impossble not to use terms that imply agency: &#8220;think&#8221;, &#8220;understand&#8221;, &#8220;learn&#8221;, &#8220;know&#8221;, &#8220;decide&#8221;, and so on. <span class="caps">AI</span> researchers use these words with very technical senses that are analogous to their usual meanings – but that aren&#8217;t the same, and that&#8217;s where things get misleading. When a person &#8220;summarises&#8221; some information, we mean that they pick out what they think is most important from the text; when an <span class="caps">LLM</span> does the same thing, it picks out the words that are statistically most clustered within the text and its training data. Are these two processes the same? They certainly don&#8217;t <i>sound</i> the same, and they often produce radically different &#8220;summaries&#8221;, because the human summariser is working from a far richer knowledge base and using different means to assess importance, often including what they know about the intended audience. It&#8217;s doing this well that&#8217;s usually taken as one of the hallmarks of intelligence. These are statistical techniques that cleave to the mean, which implies they will always <i>by design</i> produce middling answers. An amazingly insightful and creative answer is by definition unlikely, and so will be avoided <i>by design</i>.<br><br>There are other problems too. Machine learning, the science that underlies LLMs, is usually based on training from huge volumes of data. This permits impressive feats, such as being able to spot anomalies in cancer images better (in some cases) and more consistently than trained doctors. But that&#8217;s a weakness too: the idea that <i>the future will be like the past</i>, meaning that anything not in the training set runs the risk of being ignored as noise. The LLMs&#8217; training data from the internet is <i>text</i>, not validated <i>knowledge</i> in any sense. And remember that repetition increases likelihood for an <span class="caps">LLM</span>, including repeatition of nonsense. <br><br>This lies at the heart of the problem of hallucination, where AIs confidently produce startlingly incorrect text. Why is this? Because text is all they have to work with: there is no model of the world as it is, and therefore no ability to correct. The most modern LLMs are now attempting to correct this, so far with little success. <br><br>So are we seeing intelligence from LLMs? We&#8217;re seeing something that <i>presents</i> like <i>some parts of</i> such intelligence. From this the industry has extrapolated that we are, for example, about to see models demonstrating &#8220;PhD level&#8221; ability – &#8220;soon&#8221;, but there never seems to be a demonstration. One characteristic of LLMs is that they don&#8217;t spontaneously do <i>anything</i>: they wait until prompted, and then reply. Does that sound like intelligent behaviour? – no planning, no forethought, no imagination? I work with a lot of PhD-level people, and <i>none of them</i> behave this way.<br><br>Some will object that there&#8217;s lots going on in industrial labs that we don&#8217;t see. Quite possibly. Maybe the insiders are seeing things that we outsiders don&#8217;t. But the common characteristic of the systems we outsiders <i>do</i> see is systems that can perform well on certain well-prescribed and -bounded tasks, but which then fail catastrophically when used in less constrained domains. <br><br>I am a materialist: I don&#8217;t believe that there&#8217;s anything supernatural about intelligence (however one defines it), or anything privileged about running an intelligent process on a biological (rather than a silicon) substrate. But this book strikes me as another over-hyped, somewhat confused and confusing contribution to our understanding of what <span class="caps">AI</span> is. It focuses on some entirely hypothetical potential harms (intelligent autonomous machines) while largely ignoring the very real current harms of bias, accuracy, and increasing economic and digital&nbsp;disparities.
      </p>
<p>
	2/5.
	  Finished Thursday 16 January,&nbsp;2025.
	</p>
<p>
	  (Originally published on <a href="https://www.goodreads.com/review/show/6713917719?utm_medium=api&amp;utm_source=rss">Goodreads</a>.)
  </p>
</div>
		</div>
	    </article>
</div>
    <!-- Lower Navigation links -->
    <nav class="site-content navigation-post" role="navigation"><div class="previous">
		<a href="index-153.html" rel="prev">
		    <span class="meta-nav">Older Entries</span>		</a>
	    </div>
	    <div class="next">
		<a href="index-155.html" rel="next">
		    <span class="meta-nav">Newer Entries</span>		</a>
	    </div>
    </nav><!-- Page Footer --><section class="footer-sidebar clear" role="complementary"><div class="widget-block">
	    <aside class="widget"><h2 class="widget-title">Simon&nbsp;Dobson</h2>
		<div class="widget-text">Aut tace aut loquere meliora silentio</div>
	    </aside>
</div>
    </section><!-- Extra JavaScript --><!-- Site Attributions --><footer class="site-footer" role="contentinfo"><div class="site-info">
	    <p></p>
	    <p>
	      Built with free and open-source software.
	      Powered by <a href="https://getnikola.com/">Nikola</a> using a theme based on
	      <a href="https://themes.getnikola.com/v7/libretto/">Libretto</a>.
	    </p>
	    <p>
	      All content Copyright © 2010–2025 Simon Dobson and licensed under
	      <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><span class="caps">CC</span>-<span class="caps">BY</span>-<span class="caps">NC</span>-<span class="caps">SA</span>-4.0</a>
	      unless otherwise&nbsp;noted.
	    </p>
	</div>
	<div class="social">
	    <ul class="menu"></ul>
</div>
    </footer>
</body>
</html>