<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Simon Dobson (Posts about smalltalk)</title><link>https://simondobson.org/</link><description></description><atom:link href="https://simondobson.org/categories/smalltalk.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2020 &lt;a href="mailto:simon.dobson@computer.org"&gt;Simon Dobson&lt;/a&gt; </copyright><lastBuildDate>Fri, 20 Nov 2020 15:47:06 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Mainstreaming Smalltalk</title><link>https://simondobson.org/blog/2011/05/27/smalltalk/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;/p&gt;&lt;div id="heystaks_preview" style="width: 100%;height: 100%"&gt;&lt;/div&gt;
Smalltalk's influence has declined of late, at least in part because of the  "all or nothing" architecture of the most influential distribution. We've got to the stage that we could change that.
&lt;!--more--&gt;

&lt;p&gt;Some programming languages achieve epic influence without necessarily achieving universal adoption. Lisp was phenomenally influential, but has remained in an AI niche; &lt;a href="https://secure.wikimedia.org/wikipedia/en/wiki/APL_%28programming_language%29" target="_blank"&gt;APL&lt;/a&gt; gave rise to notions of bulk processing and hidden parallelism without having much uptake outside finance. Smalltalk's influence has been similar: it re-defined what it meant to be an interactive programming environment and laid the ground for many modern interface concepts, as well as giving a boost to object-oriented programming that prepared the way for C++ and Java.&lt;/p&gt;
&lt;p&gt;So why does no-one use it any more? Partly it's because of its very interactivity. Smalltalk -- and more especially &lt;a href="http://www.squeak.org" target="_blank"&gt;Squeak&lt;/a&gt;, its most prominent modern implementation -- are unusual in basing software around  complete interactive images rather than collections of source files. This isn't inherently poor -- images start immediately and encourage direct-manipulation design and interfacing -- but it's radically unfamiliar to programmers used to source code and version control. (Squeak provides version-controlled change sets to collect code outside an image, but that's still an unfamiliar structure.)&lt;/p&gt;
&lt;p&gt;But a more important issue is the all-or-nothing nature of Squeak in particular, and in fact of novel languages in general. If you want to use Squeak for a project, all the components really need to be in Squeak (although it can also use web services and other component techniques). If you want to integrate web pages, someone needs to  write an HTML rendering component, HTTP back-end and the like; for the semantic web someone needs to write XML parsers, triple stores, reasoners and the like. You can't just re-use the ones that're already out there, at least not without violating the spirit of the system somewhat. That means it plays well at the periphery with other tools, but at its core need most of the services to be written again. This is a huge buy-in. Similarly Squeak provides a great user interface for direct manipulation -- but only within its own Squeak window, rendered differently and separately from other windows on the screen. These aren't issues inherent to Smalltalk -- it's perfectly possible to imagine a Smalltalk system that used "standard" rendering (and indeed they exist) -- but the "feel" of the language is rather more isolated than is common for modern systems used to integrating C libraries and the like. At bottom it's not necessarily all that different to Java's integration with the host operating system, but the style is very much more towards separation in pursuit of uniformity and expressive power. This is a shame, because Smalltalk is in many ways a perfect development environment for novice programmers (and especially for children, who find it captivating) who are a vast source of programming innovation for small, focused services such as we find on the web ad on smartphones.&lt;/p&gt;
&lt;p&gt;So can we make Smalltalk more mainstream? Turn it into an attractive development platform for web services and mobile apps? Looking at some recent developments I think the answer is firmly &lt;em&gt;yes&lt;/em&gt; -- and without giving up on the interactivity that gives it its attraction. The key change is (unsurprisingly) the web, or more precisely the current crop of browsers that support Javascript, style sheets, SVG, dynamic HTML and the like. The browser has now arrived at a point at which it can provide a complete GUI -- complete with windows, moving and animated elements and the like -- in a standard, platform-independent and (most importantly) cloud-friendly way.&lt;/p&gt;
&lt;p&gt;What I have in mind is essentially implementing a VM for a graphical Smalltalk system, complete with interactive compiler and direct-manipulation editing, in Javascript within a browser. The "image" is then the underlying XML document and its style sheet, which can be downloaded, shared and manipulated directly. The primitives are written in Javascript, together with an engine to run Smalltalk code and objects. Objects are persisted by turning them into document elements and storing them in the DOM tree, which incidentally allows their look and feel to be customised quite simply. Crucially, it can also appeal to any current or emerging features that can appear in style sheets, the semantic web,  Javascript or embedded components: it's mainstream with respect to the other technologies being developed.&lt;/p&gt;
&lt;p&gt;Why use Smalltalk, and not Javascript directly? I simply think that the understanding we gained from Smalltalk's simplicity of programming model and embrace of direct manipulation is too valuable to lose. That's not to say that it doesn't need to be re-imagined for the web world, though. In fact, Smalltalk's simplicity and interactivity are ideally suited to the development of front-ends, components and mobile apps -- &lt;em&gt;if&lt;/em&gt; they play well with the &lt;em&gt;other&lt;/em&gt; technologies those front-ends and apps need to use, and with a suitably low barrier to entry. It's undoubtedly attractive to be able to combine local and remote components together as end-user programs, without the hassle of a traditional compile cycle, and then be able to share those mash-ups directly to the web to be shared (and, if desired, modified) by anyone.&lt;/p&gt;
&lt;p&gt;One of the things that's always attracted me about Smalltalk (and Forth, and Scheme -- and Javascript to a lesser extent) is that the code lives completely within  the dominant data structure: indeed, the code &lt;em&gt;is&lt;/em&gt; just data in most cases, and can be manipulated using data-structure operations. This is very different from the separation you get between code and data in most other languages, and gives you a huge amount of expressive power. Conversely, one of the thing that always &lt;em&gt;fails&lt;/em&gt; to attract me about these &lt;em&gt; &lt;/em&gt;same languages is their lack of any static typing and consequent dependence on testing. Perhaps these two aspects necessarily go hand in hand, although I can't think of an obvious reason why that should be.&lt;/p&gt;
&lt;p&gt;I know purists will scream at this idea, but to me it seems to go along with ideas that Smalltalk's co-inventor, Alan Kay, has expressed, especially with regard to the need to do away with closely-packaged applications and move towards a more fluid style of software:
&lt;/p&gt;&lt;blockquote&gt;The "no applications" idea first surfaced for me at PARC, when we realised that you really wanted to freely construct arbitrary combinations (and could do just that with (mostly media) objects). So, instead of going to a place that has specialised tools for doing  just a few things, the idea was to be in an "open studio" and &lt;em&gt;pull&lt;/em&gt; the resources you wanted to combine to you. This doesn't mean to say  that &lt;em&gt;e.g.&lt;/em&gt; a text object shouldn't be pretty capable -- so it's a mini app if you will -- but that it and all the other objects that intermingle with each other should have very similar UIs and have their graphics aspect be essentially totally similar as far as the graphics system is concerned -- and this goes also for user constructed objects. The media presentations I do in Squeak for my talks are good examples of the directions this should be taken for the future.&lt;/blockquote&gt;
(Anyone who has seen one of Kay's talks -- as I did at the ECOOP conference in 2000 -- can attest to how stunningly engaging they are.) To which I would add that it's equally important today that their &lt;em&gt;data&lt;/em&gt; work together seamlessly too, and with the other tools that we'll develop along the way.
&lt;p&gt;The use of the browser as a desktop isn't new, of course: it's central to &lt;a href="http://www.chromium.org/chromium-os" target="_blank"&gt;Google Chromium&lt;/a&gt; and to &lt;a href="https://simondobson.org/2011/03/jolicloud/" target="_blank"&gt;cloud-friendly Linux variants like Jolicloud&lt;/a&gt;. But it hasn't really been used so much as a development environment, or as the host for a language that lives inside the web's main document data structure. I'm not hung-up on it being Smalltalk -- a direct-manipulation front-end to &lt;a href="http://jqueryui.com/" target="_blank"&gt;jQuery UI&lt;/a&gt; might be even better -- but some form of highly interactive programming-in-the-web might be interesting to try.&lt;/p&gt;&lt;/div&gt;</description><category>Blog</category><category>javascript</category><category>programming</category><category>smalltalk</category><guid>https://simondobson.org/blog/2011/05/27/smalltalk/</guid><pubDate>Fri, 27 May 2011 07:00:29 GMT</pubDate></item><item><title>Evolving programming languages</title><link>https://simondobson.org/blog/2011/05/20/evolving/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;/p&gt;&lt;div id="heystaks_preview" style="width: 100%;height: 100%"&gt;&lt;/div&gt;
Most programming languages have fixed definitions and hard boundaries. In thinking about building software for domains we don't understand very well, a case can be made for a more relaxed, evolutionary approach to language design.
&lt;!--more--&gt;

&lt;p&gt;I've been thinking a lot about languages this week, for various reasons: mainly about the recurring theme of what are the right programming structures for systems driven by sensors, whether they're pervasive systems or sensor networks. In either case, the structures we've evolved for dealing with desktop and server systems don't feel like they're the right abstractions to effectively take things forward.&lt;/p&gt;
&lt;p&gt;A favourite example is the &lt;tt&gt;if&lt;/tt&gt; statement: first decide whether a condition is true or false, and execute one piece of code or another depending on which it is. In a sensor-driven system we often can't make this determination cleanly because of noise and uncertainty -- and if we can, it's often only probably true, and only for a particular period. So are &lt;tt&gt;if&lt;/tt&gt; statements (and &lt;tt&gt;while&lt;/tt&gt; loops and the like) actually appropriate constructs, when we can't make the decisions definitively?&lt;/p&gt;
&lt;p&gt;Whatever you think of this example (and plenty of people hate it) there are certainly differences between what we want to do between traditional and highly sensorised systems, and consequently how we program them. The question is, how do we work out what the right structures are?&lt;/p&gt;
&lt;p&gt;Actually, the question is broader than this. It should be: how do we improve our ability to develop languages that match the needs of particular computational and conceptual domains?&lt;/p&gt;
&lt;p&gt;Domain-specific languages (DSLs) have a tangled history in computer science, pitched between those who like the idea and those who prefer their programming languages general-purpose and re-usable across a &lt;em&gt;range&lt;/em&gt; of domains. There are strong arguments on both sides: general-purpose languages are more productive to learn and are often more mature, but can be less efficient and more cumbersome to apply; DSLs mean learning &lt;em&gt;another&lt;/em&gt; language that may not last long and will probably have far weaker support, but can be enormously more productive and well-targeted in use.&lt;/p&gt;
&lt;p&gt;In some ways, though, the similarities between traditional languages and DSLs are very strong. As a general rule both will have syntax and semantics defined up-front: they won't be experimental in the sense of allowing experimentation &lt;em&gt;within the language itself&lt;/em&gt;. If we don't know what we're building, does it make sense to be this definite?&lt;/p&gt;
&lt;p&gt;There are alternatives. One that I'm quite keen on is the idea of &lt;a href="https://simondobson.org/2010/05/languages-extensible-vms/" target="_blank"&gt;extensible virtual machines&lt;/a&gt;, where the primitives of a language are left "soft" to be extended as required. This style has several advantages. Firstly, it encourages experimentation by not forcing a strong division of concepts between the language we write (the target language) and the language this is implemented in (the host language): the two co-evolve. Secondly, it allows extensions to be as efficient as "base" elements, assuming we can reduce the cost of building new elements appropriately low. Thirdly, it allows multiple paradigms and approaches to co-exist within the same system, since they can share some elements while having other that differ.&lt;/p&gt;
&lt;p&gt;Another related feature is the ability to modify the compiler: that is, don't fix the syntax &lt;em&gt;or&lt;/em&gt; the way in which its handled. So as well as making the low level soft, we also make the high level soft. The advantage here is two-fold. Firstly, we can modify the forms of expression we allow to capture concepts precisely. A good example would be the ability to add concurrency control to a language: the low-level might use semaphores, but programing might demand monitors or some other construct. Modifying the high-level form of the language allows these constructs to be added if required -- and ignored if not.&lt;/p&gt;
&lt;p&gt;This actually leads to the  second advantage, that we can &lt;em&gt;avoid&lt;/em&gt; features we don't want to be available, for example not providing general recursion for languages that need to complete all operations in a finite time. This is something that's surprisingly uncommon in language design despite being common in teaching programming: leaving stuff out can have a major simplifying effect.&lt;/p&gt;
&lt;p&gt;Some people argue that syntax modification is unnecessary in a language that's sufficiently expressive, for example Haskell. I don't agree. The counter-example is actually in Haskell itself, in the form of the &lt;tt&gt;do&lt;/tt&gt; block syntactic sugar for simplifying monadic computations. This &lt;em&gt;had&lt;/em&gt; to be in the language to make it in any way usable, which implied a change of definition, and the monad designers couldn't add it without the involvement of the language "owners", even though the construct is really just a &lt;a href="https://simondobson.org/2010/06/monads-language-design-perspective/" target="_blank"&gt;re-formulation and generalisation of one common in other languages&lt;/a&gt;. There are certainly other areas in which such sugaring would be desirable to make the forms of expression simpler and more intuitive. The less well we understand a domain, the more likely this is to happen.&lt;/p&gt;
&lt;p&gt;Perhaps surprisingly, there are a couple of existing examples of systems that do pretty much what I'm suggesting. Forth is a canonical example (which explains my current work on &lt;a href="http://www.threaded-interpreter.org" target="_blank"&gt;Attila&lt;/a&gt;); Smalltalk is another, where the parser an run-time are almost completely exposed, although abstracted behind several layers of higher-level structure. Both the languages are quite old, have devoted followings, and weakly and dynamically typed -- and may have a lot to teach us about how to develop languages for new domains. They share a design philosophy of allowing a language to &lt;em&gt;evolve&lt;/em&gt; to meet new applications. In Forth, you don't so much write applications as extend the language to meet the problem; in Smalltalk you develop a model of co-operating objects that provide   direct-manipulation interaction through the GUI.&lt;/p&gt;
&lt;p&gt;In both cases the whole language, including the definition and control structures, is built in the language itself &lt;em&gt;via&lt;/em&gt; bootstrapping and cross-compilation. Both languages are compiled, but in both cases the separation between run-time and compile-time are weak, in the sense that the compiler is by default available interactively. Interestingly this doesn't stop you building "normal" compiled applications: cross-compile a system without including the compiler itself, a process that can still take advantage of any extensions added into the compiler without cluttering-up the compiled code. You're unlikely to get strictly the best performance or memory footprint as you might with a mature C compiler, but you &lt;em&gt;do&lt;/em&gt; get advantages in terms of expressiveness and experimentation which seem to outweigh these in a domain we don't understand well. In particular, it means you can evolve the language quickly, easily, and within itself, to explore the design space more effectively and find out whether your wackier ideas are actually worth pursuing further.&lt;/p&gt;&lt;/div&gt;</description><category>Blog</category><category>forth</category><category>haskell</category><category>programming</category><category>sensor networks</category><category>smalltalk</category><guid>https://simondobson.org/blog/2011/05/20/evolving/</guid><pubDate>Fri, 20 May 2011 07:00:11 GMT</pubDate></item><item><title>Languages for extensible virtual machines</title><link>https://simondobson.org/blog/2010/05/28/languages-extensible-vms/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Many languages have an underlying virtual machine (VM) to provide a more portable and convenient substrate for compilation or interpretation. For language research it's useful to be able to generate custom VMs and other language tools for different languages. Which raises the question: what's the appropriate  language for writing experimental languages?&lt;/p&gt;
&lt;!--more--&gt;

&lt;p&gt;What I have in mind is slightly more than just VMs, and more a platform for experimenting with language design for novel environments such as sensor-driven systems. As well as a runtime, this requires the ability to parse, to represent and evaluate type and semantic rules, and to provide a general framework for computation that can then be exposed into a target language as constructs, types and so forth. What's the right language in which to do all this?&lt;/p&gt;
&lt;p&gt;This isn't a simple question. It's well-accepted that the correct choice of language is vital to the success of a coding project.  One could work purely at the language level, exploring constructs and type systems without any real constraint of the real world (such as being runnable on a sensor mote). This has to some extent been traditional in programming language research, justified by the Moore's law increases in performance of the target machines. It isn't justifiable for sensor networks, though, where &lt;a href="https://simondobson.org/2010/03/things-that-wont-change/"&gt;we won't see the same phenomenon&lt;/a&gt;. If we want to prototype realistic language tools in the same framework, we need at least a run-time VM that was appropriate for these target devices; alternatively we could ignore this, focus on the language, and prototype only when we're happy with the structures, using a different framework. My gut ffeeling is that the former is preferable, if it's possible, for reasons of conceptual clarity, impact and simplicity. But even without making this decision we can consider the features of different candidate language-writing languages:
&lt;/p&gt;&lt;h3&gt;C&lt;/h3&gt;
The most obvious approach is to use C, which is run-time-efficient and runs on any potential platform. For advanced language research, though, it's less attractive because of its poor symbolic data handling. That makes it harder to write type-checking sub-systems and the like, which are essentially symbolic mathematics.
&lt;h3&gt;Forth&lt;/h3&gt;
&lt;a href="https://simondobson.org/2010/03/forth-for-sensors/"&gt;I've wondered about Forth before&lt;/a&gt;. At one level it combines the same drawbacks as C -- poor symbolic and dynamic data handling -- with the additional drawback of being unfamiliar to almost everyone.
&lt;p&gt;Forth &lt;em&gt;does&lt;/em&gt; have some redeeming features, though. Firstly, threaded interpretation means that additional layers of abstraction are largely cost-free: they run at the same speed as the language itself. Moreover there's a sense in which threaded interpretation blurs the distinction between host language and meta-language: you don't write Forth applications, you extend it towards the problem, so the meta-language &lt;em&gt;becomes&lt;/em&gt; the VM and language tool. This is something that needs some further exploration.
&lt;/p&gt;&lt;h3&gt;Scheme&lt;/h3&gt;
Scheme's advantages are its simplicity, regularity, and pretty much unrivalled flexibility in handling symbolic data. There's &lt;a href="https://simondobson.org/2010/05/cs-book-worth-reading-twice/"&gt;a long  tradition of Scheme-based language tooling&lt;/a&gt;, and so a lot of experience and libraries to make use of. It's also easy to write purely functional code, which can aid re-use.
&lt;p&gt;Scheme is dynamically typed, which can be great when exploring approaches like partial evaluation (specialising an interpreter against a particular piece of code to get a compiled program, for example).
&lt;/p&gt;&lt;h3&gt;Haskell&lt;/h3&gt;
In some ways, Haskell is the obvious language for a new language project. The strong typing, type classing and modules mean one can generate a typed meta-language. There are lots of libraries and plenty of activity in the research community. Moreover Haskell is in many ways the "mathematician's choice" of language, since one can often map mathematical concepts almost directly into code. Given thaat typing and semantics are just mathematical operations over symbols, this is a significant attraction.
&lt;p&gt;Where Haskell falls over, of course, is its runtime overheads -- mostly these days in terms of memory rather than performance. It essentially mandates a choice of target platform to be fairly meaty, which closes-off some opportunities. There are some "staged" Haskell strategies that might work around this, and one could potentially stage the code to another runtime virtual machine. Or play games like implement a Forth VM inside Haskell for experimentation, and then emit code for a &lt;em&gt;different&lt;/em&gt; Forth implementation for runtime.
&lt;/p&gt;&lt;h3&gt;Java&lt;/h3&gt;
Java remains the language &lt;em&gt;du jour&lt;/em&gt; for most new projects. It has decent dynamic data handling, poor symbolic data handling, fairly large run-time overheads and a well-stocked library for re-use. (Actually I used Java for &lt;a href="https://simondobson.org/publications/#Vanilla-GCSE99"&gt;Vanilla&lt;/a&gt;, an earlier project in a similar area.) Despite the attractions, Java feels wrong. It doesn't provide a good solution to &lt;em&gt;any&lt;/em&gt; of the constraints, and would be awkward as a platform for manipulating rules-based descriptions.
&lt;h3&gt;Smalltalk&lt;/h3&gt;
Smalltalk -- and especially &lt;a href="http://www.squeak.org"&gt;Squeak&lt;/a&gt; -- isn't a popular choice within language research, but does have a portable virtual machine, VM generation, and other nice features and libraries. The structure is also attractive, being modern and object-oriented. It's also a good platform for building interactive systems, so one could do simulation, visual programming and the like within the same framework -- something that'd be much harder with other choices. There are also some obvious connectionns between Smalltalk and pervasive systems, where one is talking about the interactions of objects in the real world.
&lt;p&gt;Where does that leave us? Nowhere, in a sense, other than with a list of characteristics of different candidate languages for language research. It's unfortunate there isn't a clear winner; alternatively, it's positive that there's a choice depending on the final direction. The worry has to be that a project like this is a moving target that moves away from the areas of strength for any choice made.&lt;/p&gt;&lt;/div&gt;</description><category>Blog</category><category>forth</category><category>haskell</category><category>moore's law</category><category>programming</category><category>smalltalk</category><category>virtual machine</category><guid>https://simondobson.org/blog/2010/05/28/languages-extensible-vms/</guid><pubDate>Fri, 28 May 2010 05:00:30 GMT</pubDate></item></channel></rss>