<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Simon Dobson (Posts about javascript)</title><link>https://simondobson.org/</link><description></description><atom:link href="https://simondobson.org/categories/javascript.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2024 &lt;a href="mailto:simoninireland@gmail.com"&gt;Simon Dobson&lt;/a&gt; </copyright><lastBuildDate>Sun, 10 Mar 2024 10:24:55 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Representing samples</title><link>https://simondobson.org/2013/07/10/representing-samples/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;p&gt;Any sensor network has to represent sampled data somehow. What would be the most friendly format for so doing?&lt;/p&gt;
&lt;!--more--&gt;

&lt;p&gt;Re-usable software has to take an extensible view of how to represent data, since the exact data that will be represented may change over time. There are several approaches that are often taken, ranging from abstract classes and interfaces (for code-based solutions) to formats such as XML for data-based approaches.&lt;/p&gt;
&lt;p&gt;Neither of these is ideal for a sensor network, for a number of reasons.&lt;/p&gt;
&lt;p&gt;A typical sensor network architecture will use different languages one the sensors and the base station, with the former prioritising efficiency and compactness and the latter emphasising connectivity to the internet and interfacing with standard tools. Typically we find C or C++ on the sensors and Java, JavaScript, Processing, or some other language on the base station. (Sometimes C or C++ too, although that's increasingly rare for new applications.) It's therefore tricky to use a language-based approach to defining data, as two &lt;em&gt;different&lt;/em&gt; versions of the &lt;em&gt;same&lt;/em&gt; structure would have to be defined and -- more importantly -- kept synchronised across changes.&lt;/p&gt;
&lt;p&gt;That suggests a data-based approach, but these tend to fall foul of the need for a compact and efficient encoding sensor-side. Storing, generating, and manipulating XML or RDF, for example, would typically be too complex and too memory-intensive for a sensor. These formats also aren't really suitable for in-memory processing -- unsurprisingly, as they were designed as transfer encodings, not primary data representations. Even though they might be attractive, not least for their friendliness to web interactions and the Semantic Web, they aren't really usable directly.&lt;/p&gt;
&lt;p&gt;There are some compromise positions, however. &lt;a href="http://www.json.org" target="_blank"&gt;JSON&lt;/a&gt; is a data notation derived initially from JavaScript (and usable directly within it) but which is sufficiently neutral to be used as an exchange format in several web-based systems. JSON essentially lets a user form objects with named fields, whose values can be strings, numbers, arrays, or other objects. (Note that this doesn't include code-valued fields, which is how JSON stays language-neutral: it can't encode computations, closures, or other programmatic features.)&lt;/p&gt;
&lt;p&gt;JSON's simplicity and commonality have raised the possibility of using it as a universal transport encoding: simpler than XML, but capable of integration with RDF, ontologies, and the Semantic Web if desired. There are several initiatives in this direction: one I came across recently is &lt;a href="http://json-ld.org/" target="_blank"&gt;JSON-LD&lt;/a&gt; (JSON for Linked Data) that seeks to integrate JSON records directly into the &lt;a href="http://linkeddata.org/" target="_blank"&gt;linked open data world&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This raises the possibility of using JSON to define the format of sensor data samples, sample collections (datasets), and the like, and linking those descriptions directly to ontological descriptions of their contents and meaning. There are some problems with this, of course. Foremost, JSON isn't very compact, and so would require more storage and wireless bandwidth than a binary format. However, one approach might be to define samples &lt;em&gt;etc&lt;/em&gt; in JSON format and then either use them directly (server-side) or compile them to something more static but more efficient for use sensor-side and for exchange. This would retain the openness but without losing performance.&lt;/p&gt;</description><category>data</category><category>framework</category><category>javascript</category><category>json</category><category>json-ld</category><category>making</category><category>project:ditch</category><category>rdf</category><category>xml</category><guid>https://simondobson.org/2013/07/10/representing-samples/</guid><pubDate>Wed, 10 Jul 2013 07:03:31 GMT</pubDate></item><item><title>The type wheel turns again</title><link>https://simondobson.org/2012/10/05/typewheel/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;p&gt;It's slightly spooky when you're discussing a topic and evidence for (or against) your position seems to spontaneously appear. The fashion for strong &lt;em&gt;versus&lt;/em&gt; weak type systems seems to change on a cycle of about a decade. It might be turning again.

&lt;!--more--&gt;

On Monday I was talking with a student who's doing a project using &lt;a href="http://nodejs.org/" target="_blank"&gt;node.js&lt;/a&gt;, looking at using it as the basis for doing elastic concurrent programs. It's the sort of project that could underpin some kinds of low-end cloud computing, letting designers use JavaScript end to end.

The discussion turned to type systems, and how Javascript's very weak view of types makes things more difficult for his project, as he will have to constantly protect against having the wrong methods called. On the other hand, it makes other things easier by letting him create proxies and other structures freely. The question is then whether strongly-typed languages are preferable to weakly-typed ones.

In a strongly-typed language, every denotable value has a type, the language ensures that all uses of those values are type-correct and generates a type error if not. A strongly statically-typed language does this purely at compile-time, and it's generally recognised by those who advocate these approaches that it's preferable to catch as many errors as possible as early as possible. It's also recognised that this isn't always possible (think Java class loaders), and so some run-time structures are also needed -- but these can be provided so as to catch problems as early as possible (when code is loaded). (See Dobson and Matthews. &lt;a href="http://www.simondobson.org/softcopy/ions-ecoop-2000.ps"&gt;Ionic types&lt;/a&gt;. In ECOOP 2000 – object-oriented programming, pages 296–312. Elisa Bertoni (ed). Volume 1850 of LNCS. Springer-Verlag. 2000.)

For some people, static typing feels too rigid: the compile will often prevent things that the programmer "knows" to be possible. In this case a looser type regime is often preferred. Strong dynamic typing checks at every operation to make sure that the values being manipulated are type-correct; weak dynamic typing does fewer checks, often only detecting problems very late; untyped or monotyped languages do few or no checks and will apply any operation to any piece of data at the programmer's instruction.

I tend to fall into the strong static typing camp -- which is slightly ironic, given that I'm currently working on &lt;a href="http://www.threaded-interpreter.org" target="_blank"&gt;untyped extensible virtual machines&lt;/a&gt;. Programmers' beliefs that they know better than the type-checker are often erroneous, the more so as code gets more complicated.

The fashion for type systems seems to follow a cycle. People are using a language with strong typing when a new kind of programming comes along, often driven by some new technology. The strong types are restrictive for this new domain (having been designed for a different world) so programmers invent or re-discover languages with dynamic typing that allow them to write the code they need to write without the difficulties of fighting a type system. In large-scale systems, programmers also like being able to evolve the data structures gradually, without having to update every user. (Doing so in the presence of strong types often doesn't work, although with care it's possible.) This leads to a widespread belief that type-checking is unnecessary, difficult, for losers, &lt;em&gt;etc&lt;/em&gt;, and that dynamic languages are the only way to go.

Then, as programs get bigger and more complicated, problems start to emerge. Typically these revolve around different parts of the system not agreeing on the exact data representation, so everyone has to check the data they receive because the language offers no guarantees that it'll be correct. (This is the down-side of being able to evolve the representation piecemeal.)  Such checks rapidly become untenable, and so programmers start thinking about whether there are automated mechanisms to improve checking -- and re-discover strong type systems.

Having been discussing this in the context of Javascript, I then stumbled across &lt;a href="http://www.typescriptlang.org" target="_blank"&gt;TypeScript&lt;/a&gt;, a Javascript extension that allows type annotations. These aren't exactly a strong type system -- they're optional, for a start -- but definitely mark a change in the way Javascript would be used, as a system with defined type structure rather than as a type free-for-all. Since Javascript occurs in a lot of systems these days -- on the front-ends, but also increasingly server-side -- this is a welcome departure. I find it hard to believe that large, long-lived component-based systems can be built in a dependable fashion using only a dynamic approach to typing. It relies too much on programmers' willingness and ability to check &lt;em&gt;everything&lt;/em&gt;, &lt;em&gt;every time&lt;/em&gt;.

Actually there &lt;em&gt;are&lt;/em&gt; strong arguments for the need for non-static run-time checks, most notably in distributed systems when you can't be sure the data you receive will be type-correct even if the compiler that generated the code thinks it is, since you generally don't have complete control over all the components and their evolutions. But this isn't an argument against strong typing in general: it still helps, even if there are small holes. Instead one perhaps needs to check types at the component boundaries so that, once admitted, you have confidence in their type-correctness. This in turn places demands on the transport protocols to be self-describing in terms of their payloads' types, and doing so supports other constructs (like type-driven computation) for free without sacrificing the benefits of the strong checks. Having some dynamism (and room for run-time failure) within a generally static seems like a decent compromise.&lt;/p&gt;</description><category>javascript</category><category>programming</category><category>type systems</category><guid>https://simondobson.org/2012/10/05/typewheel/</guid><pubDate>Fri, 05 Oct 2012 07:00:23 GMT</pubDate></item><item><title>Mainstreaming Smalltalk</title><link>https://simondobson.org/2011/05/27/smalltalk/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;div id="heystaks_preview" style="width: 100%;height: 100%"&gt;&lt;/div&gt;
Smalltalk's influence has declined of late, at least in part because of the  "all or nothing" architecture of the most influential distribution. We've got to the stage that we could change that.

&lt;!--more--&gt;

Some programming languages achieve epic influence without necessarily achieving universal adoption. Lisp was phenomenally influential, but has remained in an AI niche; &lt;a href="https://secure.wikimedia.org/wikipedia/en/wiki/APL_%28programming_language%29" target="_blank"&gt;APL&lt;/a&gt; gave rise to notions of bulk processing and hidden parallelism without having much uptake outside finance. Smalltalk's influence has been similar: it re-defined what it meant to be an interactive programming environment and laid the ground for many modern interface concepts, as well as giving a boost to object-oriented programming that prepared the way for C++ and Java.

So why does no-one use it any more? Partly it's because of its very interactivity. Smalltalk -- and more especially &lt;a href="http://www.squeak.org" target="_blank"&gt;Squeak&lt;/a&gt;, its most prominent modern implementation -- are unusual in basing software around  complete interactive images rather than collections of source files. This isn't inherently poor -- images start immediately and encourage direct-manipulation design and interfacing -- but it's radically unfamiliar to programmers used to source code and version control. (Squeak provides version-controlled change sets to collect code outside an image, but that's still an unfamiliar structure.)

But a more important issue is the all-or-nothing nature of Squeak in particular, and in fact of novel languages in general. If you want to use Squeak for a project, all the components really need to be in Squeak (although it can also use web services and other component techniques). If you want to integrate web pages, someone needs to  write an HTML rendering component, HTTP back-end and the like; for the semantic web someone needs to write XML parsers, triple stores, reasoners and the like. You can't just re-use the ones that're already out there, at least not without violating the spirit of the system somewhat. That means it plays well at the periphery with other tools, but at its core need most of the services to be written again. This is a huge buy-in. Similarly Squeak provides a great user interface for direct manipulation -- but only within its own Squeak window, rendered differently and separately from other windows on the screen. These aren't issues inherent to Smalltalk -- it's perfectly possible to imagine a Smalltalk system that used "standard" rendering (and indeed they exist) -- but the "feel" of the language is rather more isolated than is common for modern systems used to integrating C libraries and the like. At bottom it's not necessarily all that different to Java's integration with the host operating system, but the style is very much more towards separation in pursuit of uniformity and expressive power. This is a shame, because Smalltalk is in many ways a perfect development environment for novice programmers (and especially for children, who find it captivating) who are a vast source of programming innovation for small, focused services such as we find on the web ad on smartphones.

So can we make Smalltalk more mainstream? Turn it into an attractive development platform for web services and mobile apps? Looking at some recent developments I think the answer is firmly &lt;em&gt;yes&lt;/em&gt; -- and without giving up on the interactivity that gives it its attraction. The key change is (unsurprisingly) the web, or more precisely the current crop of browsers that support Javascript, style sheets, SVG, dynamic HTML and the like. The browser has now arrived at a point at which it can provide a complete GUI -- complete with windows, moving and animated elements and the like -- in a standard, platform-independent and (most importantly) cloud-friendly way.

What I have in mind is essentially implementing a VM for a graphical Smalltalk system, complete with interactive compiler and direct-manipulation editing, in Javascript within a browser. The "image" is then the underlying XML document and its style sheet, which can be downloaded, shared and manipulated directly. The primitives are written in Javascript, together with an engine to run Smalltalk code and objects. Objects are persisted by turning them into document elements and storing them in the DOM tree, which incidentally allows their look and feel to be customised quite simply. Crucially, it can also appeal to any current or emerging features that can appear in style sheets, the semantic web,  Javascript or embedded components: it's mainstream with respect to the other technologies being developed.

Why use Smalltalk, and not Javascript directly? I simply think that the understanding we gained from Smalltalk's simplicity of programming model and embrace of direct manipulation is too valuable to lose. That's not to say that it doesn't need to be re-imagined for the web world, though. In fact, Smalltalk's simplicity and interactivity are ideally suited to the development of front-ends, components and mobile apps -- &lt;em&gt;if&lt;/em&gt; they play well with the &lt;em&gt;other&lt;/em&gt; technologies those front-ends and apps need to use, and with a suitably low barrier to entry. It's undoubtedly attractive to be able to combine local and remote components together as end-user programs, without the hassle of a traditional compile cycle, and then be able to share those mash-ups directly to the web to be shared (and, if desired, modified) by anyone.

One of the things that's always attracted me about Smalltalk (and Forth, and Scheme -- and Javascript to a lesser extent) is that the code lives completely within  the dominant data structure: indeed, the code &lt;em&gt;is&lt;/em&gt; just data in most cases, and can be manipulated using data-structure operations. This is very different from the separation you get between code and data in most other languages, and gives you a huge amount of expressive power. Conversely, one of the thing that always &lt;em&gt;fails&lt;/em&gt; to attract me about these &lt;em&gt; &lt;/em&gt;same languages is their lack of any static typing and consequent dependence on testing. Perhaps these two aspects necessarily go hand in hand, although I can't think of an obvious reason why that should be.

I know purists will scream at this idea, but to me it seems to go along with ideas that Smalltalk's co-inventor, Alan Kay, has expressed, especially with regard to the need to do away with closely-packaged applications and move towards a more fluid style of software:
&lt;blockquote&gt;The "no applications" idea first surfaced for me at PARC, when we realised that you really wanted to freely construct arbitrary combinations (and could do just that with (mostly media) objects). So, instead of going to a place that has specialised tools for doing  just a few things, the idea was to be in an "open studio" and &lt;em&gt;pull&lt;/em&gt; the resources you wanted to combine to you. This doesn't mean to say  that &lt;em&gt;e.g.&lt;/em&gt; a text object shouldn't be pretty capable -- so it's a mini app if you will -- but that it and all the other objects that intermingle with each other should have very similar UIs and have their graphics aspect be essentially totally similar as far as the graphics system is concerned -- and this goes also for user constructed objects. The media presentations I do in Squeak for my talks are good examples of the directions this should be taken for the future.&lt;/blockquote&gt;
(Anyone who has seen one of Kay's talks -- as I did at the ECOOP conference in 2000 -- can attest to how stunningly engaging they are.) To which I would add that it's equally important today that their &lt;em&gt;data&lt;/em&gt; work together seamlessly too, and with the other tools that we'll develop along the way.

The use of the browser as a desktop isn't new, of course: it's central to &lt;a href="http://www.chromium.org/chromium-os" target="_blank"&gt;Google Chromium&lt;/a&gt; and to &lt;a href="https://simondobson.org/2011/03/jolicloud/" target="_blank"&gt;cloud-friendly Linux variants like Jolicloud&lt;/a&gt;. But it hasn't really been used so much as a development environment, or as the host for a language that lives inside the web's main document data structure. I'm not hung-up on it being Smalltalk -- a direct-manipulation front-end to &lt;a href="http://jqueryui.com/" target="_blank"&gt;jQuery UI&lt;/a&gt; might be even better -- but some form of highly interactive programming-in-the-web might be interesting to try.</description><category>javascript</category><category>programming</category><category>smalltalk</category><guid>https://simondobson.org/2011/05/27/smalltalk/</guid><pubDate>Fri, 27 May 2011 07:00:29 GMT</pubDate></item></channel></rss>