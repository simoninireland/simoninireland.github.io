<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Simon Dobson (Posts about finance)</title><link>https://simondobson.org/</link><description></description><atom:link href="https://simondobson.org/categories/finance.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2023 &lt;a href="mailto:simoninireland@gmail.com"&gt;Simon Dobson&lt;/a&gt; </copyright><lastBuildDate>Tue, 19 Dec 2023 12:45:04 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Sensing financial problems</title><link>https://simondobson.org/2010/04/27/sensing-financial-problems/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;p&gt;Just as we can think of large-scale, detailed financial modeling as &lt;a href="https://simondobson.org/2010/04/computer-science-financial-crisis/"&gt;an exercise in simulation and linked data&lt;/a&gt;, we can perhaps also see the detection of hazards as an exercise in sensor fusion and pervasive computing, turning a multitude of sensor data into derived values for risk and/or situations requiring attention. There's a wealth of research in these areas that might be applicable.

&lt;!--more--&gt;

Environmental and other sensing is intended to make real-world phenomena accessible directly to computers. Typically we simply collect data and archive it for later analysis; increasingly we also move decision-making closer to the data in order to take decisions in close to real time about the ways in which the data is sensed in the future (so-called &lt;em&gt;adaptive&lt;/em&gt; sensing) or to allow the computers to respond directly in terms of the services they provide (&lt;em&gt;autonomic&lt;/em&gt; or &lt;em&gt;pervasive&lt;/em&gt; systems).

Can we treat the financial markets as the targets of sensing? Well, actually, we already do. An index like the &lt;a href="http://www.ftse.com/"&gt;FTSE&lt;/a&gt; is basically providing an abstracted window onto the behaviour of an underlying process -- in this case a basket of shares from the top 100 companies listed on the London exchange -- that can be treated as an observation of an underlying phenomenon. This further suggests that the technology developed for autonomic and pervasive computing could potentially be deployed to observe financial markets.

In some sense, pricing is already based on sensing. A put option, for example -- where the buyer  gains the right to compel  the seller to buy some goods at some  point in the future at some  defined cost -- will, if exercised, have a definite value to the buyer &lt;em&gt;then&lt;/em&gt; (when executed). It's value &lt;em&gt;now&lt;/em&gt; (when sold) will  be less than this, however,  because of the risk that the option will not be exercised (because, for  example, the buyer can sell the goods to someone else for more than the  seller has contracted to pay for them). Deciding what value to assign to  this contract is then a function over the expected future behaviour of  the market for the underlying goods. This expectation is formed in part by observing the behaviour of the market in the past, combined with the traders' knowledge of (or guesses about) external factors that might affect the price.

These external factors are referred to in pervasive computing as &lt;em&gt;context&lt;/em&gt;, and are used to condition the ways in which sensor streams are interpreted (see &lt;a href="https://simondobson.org/research/publications/#ContextIsCentral"&gt;Coutaz &lt;em&gt;et alia&lt;/em&gt;&lt;/a&gt; for an overview). One obtains context from a number of sources, typically combining expert knowledge and sensor data. A typical pervasive system will build and maintain a &lt;em&gt;context model&lt;/em&gt; bringing together all the information it knows about in a single database. We can further decompose context into &lt;em&gt;primary&lt;/em&gt; context sensed directly from a data source and &lt;em&gt;secondary&lt;/em&gt; context derived by some reasoning process. If we maintain this database in a semantically tractable format such as &lt;a href="http://www.w3.org/RDF/"&gt;RDF&lt;/a&gt;, we can then reason about what's happening in order to classify what's happening in the real world (&lt;em&gt;situation recognition&lt;/em&gt;) and respond accordingly. Crucially, this kind of context processing can treat &lt;em&gt;all&lt;/em&gt; context as being sensed, not just real-world data: we often "sense" calendars, for example, to look for clues about intended activities and locations, integrating web mining into sensing. Equally crucially, we use context as evidence to support model hypotheses ("Simon is in a meeting with Graeme and Erica") given by the situations we're interested in.

A lot of institutions already engage in automated trading, driven by the behaviour of indices and individual stocks. Cast into sensor-driven systems terminology, the institutions develop a number of situations of interest (a time to buy, hold, sell and so forth for different portfolios) and recognise which are currently active using primary context sensed from the markets (stock prices, indices) and secondary context derived from this sensed data (stock plummeting, index in free-fall). Recognising a situation leads to a particular behaviour being triggered.

Linked data opens-up richer opportunities for collecting context, and so for the management of individual products such as mortgages. We could, for example, sense a borrower's repayment history (especially for missed payments) and use this both to generate secondary context (revised risk of default) and to identify situations of interest (default, impaired, at-risk). Banks do this already, of course, but there are advantages to the sensor perspective. For one, context-aware systems show us that it's the richness of links between  context that is the key to its usefulness. The more links we have, the more semantics we have over which to reason. Secondly, migrating to a context-aware platform means that additional data streams, inferences and situations can be added as-and-when required, without needing to re-architect the system. Given the ever-increasing amount of information available on-line, this is certainly something that might become useful.

Of course there are massive privacy implications here, not least in the use of machine classifiers to evaluate -- and of course inevitably &lt;em&gt;mis&lt;/em&gt;-evaluate -- individuals' circumstances. It's important to realise that this is going on anyway and isn't going to go away: the rational response is therefore to make sure we use the best approaches available, and that we enforce audit trails and transparency to interested parties. Credit scoring systems are notoriously opaque at present -- I've had experience of this myself recently, since credit history doesn't move easily across borders -- so there's a screaming need for systems that can explain and justify their decisions.

I suspect that the real value of a sensor perspective comes not from considering an individual institution but rather an entire marketplace. To use an example I'm familiar with from Ireland, one bank at one stage pumped its share price by having another bank make a large deposit -- but then loaned this second bank the money to fund the deposit. Contextualised analysis might have picked this up, for example by trying to classify what instruments or assets each transaction referred to. Or perhaps not: no system is going to be fully robust against the actions of ingenious insiders. The point is not to suggest that there's a foolproof solution, but rather to increase the amount and intelligence of surveillance in order to raise the bar. Given the costs involved in unwinding failures when detected late, it might be an investment worth making.&lt;/p&gt;</description><category>Blog</category><category>context</category><category>finance</category><category>ireland</category><category>linked data</category><category>risk</category><guid>https://simondobson.org/2010/04/27/sensing-financial-problems/</guid><pubDate>Tue, 27 Apr 2010 12:32:57 GMT</pubDate></item><item><title>What computer science can learn from finance</title><link>https://simondobson.org/2010/04/16/computer-science-learn-finance/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;p&gt;Science should be a two-way street. In the same way that we might view the financial system as &lt;a href="https://simondobson.org/2010/04/computer-science-financial-crisis/"&gt;a computational model that can be simulated&lt;/a&gt;, there are undoubtedly things that computing can learn from finance. In particular, a lot of financial instruments and techniques evolved because of uncertainty and risk: issues that are absolutely a part of computer science in general and of &lt;a href="https://simondobson.org/2010/02/216/"&gt;sensorised systems in particular&lt;/a&gt;. The financial crunch hasn't invalidated the  significance that these techniques may have for computer science and systems architecture.

&lt;!--more--&gt;

There 's an increasing acceptance that economics as a whole has lessons for computing. The connection may not be obvious, but if one considers that most modern systems of any scale are built from components, and often from agents whose goals are not necessarily completely aligned and whose actions need not be trusted, one begins to see how a model that assumes only self-interest might have relevance. Typically economics is used to provide models for large-scale behaviour, rather than being treated as a way to formulate or program the agents themselves. (For a survey of recent results see Neumann, Baker, Altmann and Rana (eds). &lt;a href="http://www.springer.com/birkhauser/computer+science/book/978-3-7643-8896-6" target="_blank"&gt;Economic models and algorithms for distributed systems&lt;/a&gt;. Birkhäuser. 2010.)

How about the individual instruments, though?

Let's take a step back and think what a financial instrument actually &lt;em&gt;is&lt;/em&gt;, or rather what it's goals are. To make money, clearly, but making money is easy &lt;em&gt;if&lt;/em&gt; you know the exact circumstances in which a transaction will take place. It's generally accepted in the economics of ordinary trade, for example, that &lt;em&gt;both&lt;/em&gt; sides of the transaction win from the trade: the seller will only sell if the goods sell for more than he spent in creating them, while the buyer will only buy if the goods have a higher utility value to him than the cost of their purchase. (It's interesting that it's necessary to point this out, since a lot of people tacitly assume that trade is only good for one side or the other, not for both.) The different between this sort of economic activity and financial instruments such as shares and derivatives is that the traders know (most of) the circumstances that affect their valuations, whereas the value of a mortgage or share is affected by events that haven't happened yet.

If we represent instruments as computational objects, then we can look at the ways in which this uncertainty might be managed. A common way is to identify the risks that affect the value of an instrument, and &lt;em&gt;hedge&lt;/em&gt; them. To hedge a risk, you find another instrument whose value will change in a way that balances that of the initial risk. The idea is that a loss on the first is compensated, at least in part, by a gain on the second.

The best example I can find -- given my very limited understanding -- is airline fuel. An airline knows it needs fuel in the future, and can even estimate how much it will need, but doesn't want to buy it all up-front because things might change. This means that the airline doesn't know how much the fuel will cost, since the price may change. A large increase would cost money since tickets already sold would reflect the earlier, lower fuel price. Passing this on later as a surcharge is extremely unpopular. What the airline &lt;em&gt;can&lt;/em&gt; do is to buy a fuel future, a &lt;em&gt;call option&lt;/em&gt;, that gives it the right to buy fuel from someone at a fixed price per litre. That is, someone guarantees that they will sell the airline the fuel it needs in (say) six months at a given price. The option itself costs money, above and beyond the cost of the fuel, but if the prices are right the airline is insulated against surges in the fuel price. If in six months the cost of fuel is higher than the cost in the call option, the airline exercises the option, buys the fuel, and makes money &lt;em&gt;versus&lt;/em&gt; what it would have paid; if the price is less than that in the call option, the airline just writes-off the cost of the option and buys the fuel in the market. Either way the airline caps its exposure and so controls its future risk. (If this all sounds one-sided, the entity selling the option to the airline needs to make money too -- perhaps by having a source of fuel at a known price, or having a stockpile on hand, or simply betting that the prices will move in a certain way.)

There is already experience in writing financial instruments, including derivatives and the like, using programming languages. (See, for example, Peyton Jones and Eber. Composing contracts: an adventure in financial engineering. Proc. ICFP. Montreal, CA. 2000.) Instruments represented as computational objects can be linked to their hedges. If we're &lt;a href="https://simondobson.org/2010/04/computer-science-financial-crisis/"&gt;simulating the the market&lt;/a&gt;, we can also simulate the values of hedges and see under what circumstances their values would fall alongside the original assets. That shows up risks of large crashes. At present this is done at a coarse statistical level, but if we link instruments to their metadata we can get a much finer simulation.

We can potentially use a similar technique for &lt;em&gt;any&lt;/em&gt; system that's exposed to future uncertainty, though. Systems that do  inference have to live the risk that their inferences will be wrong. In a pervasive computing system such as a smart building, for example, one typically looks at a range of sensors to try to determine what's happening and respond accordingly (by opening doors, providing information, sounding alarms or whatever else is needed by the application). Most such actions occur by inference, and can typically be wrong.

How might the lessons of finance help? We have a process that is dealing with future uncertainty, and whose utility is governed by how well it manages to address that uncertainty relative to what's "really happening" in the world. If we rely on our single inference process, and it makes a mistake -- as it inevitably will -- we're left completely exposed: the utility of the system is reliant on the correctness of the single inference function. Put in the terms above, it isn't hedged.

So we might require each inference process to come with a hedge. That is to say, each process not only specifies &lt;em&gt;what&lt;/em&gt; &lt;em&gt;should happen&lt;/em&gt; as a result of its determination of the current situation; it also specifies &lt;em&gt;what should happen if we get it wrong&lt;/em&gt;, if later evidence shows that the inference we made was wrong. This might be something simple like reversing the action we took: we turned the lights on because we thought a room was occupied, and in mitigation if we're wrong we turn the lights off again. The "cost" of this action is some wasted power. Some processes aren't reversible, of course: if we (think we) recognise someone at a door, and open it to admit them, and then discover we made a mistake and it's not the person we thought, just locking the door again won't work. We could however, take some other action (sound an alarm?), and accept a "cost" that is expressed in terms of the inappropriate or malicious actions the person might have taken as a result of our mistake. Moreover because we've combined the action and its hedge, we can assess the potential costs involved and perhaps change the original inference algorithm to for example require more certainty.

Essentially each behaviour that's triggered comes with another, related behaviour that's triggered in the event that the first one shouldn't have been. There are some interesting lifecycle issues involved turning this into a programming system, since the lifetime of the hedging behaviour might be longer than that of the original behaviour: even after the person has left the room, we might want to sound the alarm if we realise we made a mistake letting them in. The costs of mistakes might also be a function of time, so that problems detected later are more costly.

The point here is not that pervasive and sensor systems can get things wrong -- of course they can -- but that we need to design systems on the assumption that they &lt;em&gt;will&lt;/em&gt; get things wrong, and account for the costs (financial and otherwise) that this exposes us to and the actions we can take to mitigate them. The financial system does this: it recognises that there is uncertainty in the world and tries to construct a network of agents which will gain value regardless of the uncertain events that happen. The process isn't perfect, as we've seen in recent financial events, but it's at least a recognition within the system of the impact that uncertainty will have. That's something we could learn in, and incorporate into, computer science and systems engineering.&lt;/p&gt;</description><category>Blog</category><category>finance</category><category>uncertainty</category><guid>https://simondobson.org/2010/04/16/computer-science-learn-finance/</guid><pubDate>Fri, 16 Apr 2010 05:00:58 GMT</pubDate></item><item><title>Computer science and the financial crisis</title><link>https://simondobson.org/2010/04/09/computer-science-financial-crisis/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;p&gt;Many people expected a financial crisis; many also expected it to be caused by automated trading strategies driving share prices, As it turned out, that aspect of computing in finance didn't behave as badly as expected, and the problems arose in the relatively computing-free mortgage sector. Is there any way computing could have helped, or could help avoid future crises? &lt;!--more--&gt;

&lt;!-- more --&gt;

Over brunch earlier this week my wife &lt;a href="http://www.facebook.com/profile.php?id=670070295"&gt;Linda&lt;/a&gt; was worrying about the credit crunch. It's especially pressing since we're in Ireland at the moment, and the whole country is convulsed with the government's setting-up of the &lt;a href="http://www.nama.ie"&gt;National Asset Management Agency (NAMA)&lt;/a&gt; to take control of a huge tranche of bad debts from the Irish banks. She asked me, "what can you do, as a computer scientist, to fix this?" Which kind of puts me on the spot thinking about a topic about which I know very little, but it got me thinking that there may be areas where programming languages and data-intensive computing might be relevant for the future, at least. So here goes....

The whole financial crisis has been horrendously complex, of course, so let's start by focusing on the area I know best: the Irish "toxic tiger" crash. This has essentially been caused by banks making loans to developers to finance housing and commercial property construction, both of which were encouraged through the tax system. Notably the crash was &lt;em&gt;not&lt;/em&gt; caused by loans to sub-prime consumers and subsequent securitisation, and so is substantively different to the problems in the US (although triggered by them through tightening credit markets). The loans were collateralised on the present (or sometimes future, developed) value of the land -- and sometimes on "licenses to build" on land rather than the land itself --  often cross-collateralised with several institutions and developments, and financed by borrowings from the capital markets rather than from deposits (of which Ireland, as a country of 4M people, has rather little). As capital availability tightened across 2008-9 the property market stalled, the value of the land dropped (by 80% in some cases, and by 100% for the licenses to build), and the banks have been left with bad loans and capital shortcomings in the range of at least EUR60B which now the government, for reasons strongly suspected to be political and ideological rather than being necessarily in the best interests of the taxpayer, are taking onto the public balance sheet rather than allowing them to be carried by the banks' owners and bondholders. The crash has also, as might be expected, revealed enormous shortcomings in banks' risk management, their understanding of their own holdings and exposures, some unbelievably lax supervision by the authorities, and a lot of suspected corruption and corporate fraud.

(The above is a gross simplification, of course. The &lt;a href="http://www.irisheconomy.ie"&gt;Irish Economy blog&lt;/a&gt; is the best source of details, being run by a large fraction of Ireland's leading academic economists who have been depressingly accurate as to how the crisis would unfold.)

So what can computer science say about this mess? To start with, there are several key points we can pull out of the above scenario:
&lt;/p&gt;&lt;ol&gt;
    &lt;li&gt;&lt;em&gt;Modelling.&lt;/em&gt; Its hard to know what the effect of a given stressor would be on the system: what &lt;em&gt;exactly&lt;/em&gt; happens if there's sector-wide unemployment, or a localised fall in purchasing?. Most banks seem to have conducted modelling only at the grossed statistical level.&lt;/li&gt;
    &lt;li&gt;&lt;em&gt;Instrument complexity.&lt;/em&gt; Different financial instruments respond to stimuli in different ways. A classic example is where unpaid interest payments are rolled-up into the principal of a mortgage, changing its behaviour completely. Parcelling-up these instruments makes their analysis next to impossible.&lt;/li&gt;
    &lt;li&gt;&lt;em&gt;Traceability.&lt;/em&gt; The same assets appear in different places without being detected up-front, which makes all the instruments involved significantly more risky and less valuable.&lt;/li&gt;
    &lt;li&gt;&lt;em&gt;Public trust.&lt;/em&gt; The "stress tests" conducted by regulators were conducted in secret without independent scrutiny, as have been the valuations applied to the bad loans. The public is therefore being asked to sign-off on a debt of which it knows nothing.&lt;/li&gt;
&lt;/ol&gt;
Clearly this is very complicated, and statistical modelling is only going to provide us with an overview. The simplifications needed to get the mathematics to work will be heroic, despite the power of the underlying analytic techniques.

So let's treat the problem as one of simulation rather than analysis.A mortgage is generally treated as &lt;em&gt;data&lt;/em&gt; with a particular principal, interest rate, default rate and so on. It can however also be viewed as &lt;em&gt;process&lt;/em&gt;, a computational object: at each accounting period (month) it takes in money (mortage payment) and consequently has a value going forward. There is a risk that the payment won't come in, which changes the risk profile and risk-weighted value of the mortgage. It will respond in a particular way, perhaps by re-scheduling payments (increasing the term of the mortgage), or trying to turn itself into a more liquid object like cash (foreclosing on the loan and selling the house), Foreclosure involves interacting with other objects that model the potential behaviour of buyers, to indicate how much cash the foreclosure brings in: in a downturn, the liklihood of payment default increases and  the cash value of mortgages forclosed-upon similarly reduces.

The point is that there's relatively little human, &lt;em&gt;banking&lt;/em&gt; intervention involved here: it's mostly computational. One could envisage a programming language for expressing the behaviours of mortgages, which defines their responses to different stimuli and defines an expected present value for the mortgage discounted by the risks of default, the amount recoverable by foreclosure, and so on.

So the first thing computer science can tell us about the financial crash is that the underlying instruments are essentially computational, and can be represented as code. This provides a reference model for the behaviour we should expect from a particular instrument exposed to particular stimuli, expressed clearly as code.

We can go a stage further. If loans are securitised -- packaged-up into another instrument whose value is derived from that of the underlying assets, like a futures contract -- then the value of the derivative can be computed from the values of the assets underlying it. Derivatives are often horrifically complicated, and their might be significant advantages to be had in expressing their behaviours as code.

How do we get the various risk factors? Typically this is done at a gross level across an entire population, but it need not be. We now live in an exabyte era. We can treat the details of the underlying asset as metadata on the code: the location of a house, its size and price history, the owners' jobs and so forth. We currently have this data held privately, and as statistical aggregates, but there's no reason why we can't have associate the &lt;em&gt;actual&lt;/em&gt; details to &lt;em&gt;each&lt;/em&gt; loan or instrument, and therefore to each derivative constructed from them. This after all is what linked data is all about. means that each financial instrument is inherently computational, and carries with it all the associated metadata. This little package &lt;em&gt;is&lt;/em&gt; the loan, to all intents and purposes.

So the second thing computer science can tell us is that we can link instruments, assets and data together, and track between them, using the standard tools and standards of the semantic web. This means we can query them at a high semantic level, and us these queries to extract partitions of the data we're interested in examining further. There's no scientific reason that this can't be done across an entire market, not simply within a single institution.

The net result of the above is that, given this coding and linking, &lt;em&gt;the financial system can be run in simulation&lt;/em&gt;. We can conduct stress tests at a far finer resolution by for example running semantic queries to extract a population of interest, making them all redundant (in simulation), and seeing what happens not only to their loans, but to the securitised products based on them -- since everythings just a computation. Multiple simulations can be run to explore different future scenarios, based on different risk weightings an so forth.

(This sounds like a lot of data, so let's treat the UK housing market as a &lt;a href="http://en.wikipedia.org/wiki/Fermi_problem"&gt;Fermi problem&lt;/a&gt; and see if it's feasible. There are 60M people in the UK. Assume 2-person families on average, yielding 30M domestic houses to be mortgaged. Some fraction of these are mortgage-free, say one third, leaving 20M mortgages. The workforce is around 40M working in firms with an average of say 20 employees, each needing premises, yielding a further 2M commercial mortages. If each mortgage needs 10Kb of data to describe it, we have 22M objects requiring about 250Tb of data: a large but not excessive data set, especially when most objects execute the same operations and share a lot of common data: certainly well within the simulation capabilities of cloud computing. So we're not in computationally infeasible territory here.)

We can actually go a few stages further. Since we have a track-back from instrument to metadata, we can &lt;em&gt;learn&lt;/em&gt; the risks over time by observing what happens to specific cohorts of borrowers exposed to different stimuli and stresses. Again, linked data lets us identify the patterns of behaviour happening in other data sets, such as regional unemployment (now &lt;a href="http://data.gov.uk"&gt;directly available online in the UK&lt;/a&gt; and elsewhere). The more data goes online the easier it is to spot trends, and the easier and finer one can learn the behaviors the system is exhibiting. As well as running the simulation &lt;em&gt;forwards&lt;/em&gt; to try to see what's coming, we can run it &lt;em&gt;backwards&lt;/em&gt; to learn and refine parameters that can then be used to improve prediction.

Therefore the third think computer science can tell us is that the financial markets as a whole are potentially a rich source of machine learning and statistical inference, which can be conducted using standard techniques from the semantic web.

Furthermore, we can conduct simulations in the open. If banks have to represent their holdings as code, and have to link to (some of) the metadata associated with a loan, then regulators can run simulations and publish their results. There's a problem of commercial confidentiality, of course, but one can lock-down the fine detail of metadata if required (identifying owners by postcode and without names, for example). If each person, asset and loan has a unique identifier, it's easier to spot cross-collateralisations and other factors that weaken the values of instruments, without needing to be able to look inside the asset entirely. This exposes a bank's holdings in metadata terms -- residential loans in particular areas -- but that's probably no bad thing, given that the lack of information about securitise contributed to the fall.

This is the last thing computer science can tell us. Open-source development suggests that having more eyes on a problem reduces the number, scope and severity of bugs, and allows for re-use and re-purposing far beyond what might be expected &lt;em&gt;a priori&lt;/em&gt;. For a market, more eyes means a better regulatory and investor understanding of banks' positions, and so (in principle) a more efficient market.

For all I know, banks already do a lot of this internally, but making it an open process could go a long way to restore confidence in both taxpayers and future investors. There's no time like a crash to try out new ideas.</description><category>Blog</category><category>e-science</category><category>finance</category><category>ireland</category><category>nama</category><guid>https://simondobson.org/2010/04/09/computer-science-financial-crisis/</guid><pubDate>Fri, 09 Apr 2010 18:55:11 GMT</pubDate></item></channel></rss>