<!DOCTYPE html>
<html prefix="
	og: http://ogp.me/ns# article: http://ogp.me/ns/article#
    " vocab="http://ogp.me/ns" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Posts about programming | Simon Dobson</title>
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
<link rel="stylesheet" href="assets/css/normalize.css">
<link rel="stylesheet" href="assets/css/main.css">
<link href="../../assets/css/baguetteBox.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/rst_base.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_rst.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/fonts.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/theme.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../../rss.xml">
<link rel="canonical" href="https://simondobson.org/categories/programming/">
<link rel="icon" href="../../images/favicon.png" sizes="32x32">
<link rel="next" href="index-4.html" type="text/html">
<!--[if lt IE 9]><script src="../../assets/js/html5shiv-printshiv.min.js"></script><![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-10943215-1"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-10943215-1');
</script><link rel="alternate" type="application/rss+xml" title="RSS for tag programming" hreflang="en" href="../programming.xml">
</head>
<body>
  <a href="#page-content" class="sr-only sr-only-focusable">
    Skip to main content
  </a>

  

  <section id="header"><a href="../../">
      <div class="logo">
	  <div id="nologoimage">
	    Simon Dobson
	  </div>
      </div>
    </a>
  </section><section id="socialNav"><!-- Navigation Menu - on top on small screens, down the left on larger --><div class="navlinks">
<!--
      <a href="/">
	<div id="titleauth">
	    by Simon Dobson
	</div>
      </a>
-->

      <!-- Navigation links (hidden by default) -->
      <div id="navmenuitems">
	      <a href="../../index.html" title="Home">
	<span class="menuitemtext">Home</span>
	<span class="menuitemicon"><i class="fa fa-home"></i></span>
      </a>
      <a href="../../personal/" title="About me">
	<span class="menuitemtext">About me</span>
	<span class="menuitemicon"><i class="fa fa-user"></i></span>
      </a>
      <a href="../../research/" title="Research">
	<span class="menuitemtext">Research</span>
	<span class="menuitemicon"><i class="fa fa-lightbulb"></i></span>
      </a>
      <a href="../../development/projects/" title="Software">
	<span class="menuitemtext">Software</span>
	<span class="menuitemicon"><i class="fa fa-cogs"></i></span>
      </a>
      <a href="../../writing/" title="Writing">
	<span class="menuitemtext">Writing</span>
	<span class="menuitemicon"><i class="fa fa-feather"></i></span>
      </a>
      <a href="../../personal/contact/" title="Contact">
	<span class="menuitemtext">Contact</span>
	<span class="menuitemicon"><i class="fa fa-info-circle"></i></span>
      </a>
      <a href="../../rss.xml" title="RSS">
	<span class="menuitemtext">RSS</span>
	<span class="menuitemicon"><i class="fa fa-rss"></i></span>
      </a>
  <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">
     <img alt="Creative Commons License CC-BY-NC-SA-4.0" style="border-width:0" src="../../images/cc-by-nc-sa-4.0.png"></a>
  
  

      </div>

      <!-- "Hamburger menu" / "Bar icon" to toggle the navigation links -->
      <a href="javascript:void(0);" id="hamburger" class="icon" onclick="toggleNav()">
	<i class="fa fa-bars">
	</i>
      </a>
    </div>
  </section><section class="page-content"><div class="content" rel="main">
    <header><h1>Posts about programming</h1>
        <div class="metadata">
                            <p class="feedlink">
                                    <a href="../programming.xml" hreflang="en" type="application/rss+xml">RSS feed</a>

                </p>

            
        </div>
    </header><div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="../../2020/12/09/backporting-python-types/" class="u-url">Backporting Python type annotations</a></h1>

        
        <div class="metadata">
            <p class="dateline"><a href="../../2020/12/09/backporting-python-types/" rel="bookmark"><i class="fa fa-clock"></i> <time class="published dt-published" datetime="2020-12-09T10:45:43Z" title="2020-12-09 10:45">2020-12-09 10:45</time></a></p>

                <p class="commentline"><i class="fa fa-comment"></i>         <a href="../../2020/12/09/backporting-python-types/#disqus_thread" data-disqus-identifier="cache/posts/2020/12/09/backporting-python-type-annotations.html">Comments</a>


        </p>
</div>
    </header><div class="p-summary entry-summary">
    <div>
<p>I recently added type annotations to my
<a href="../../development/epyc/"><code>epyc</code></a> and
<a href="../../development/epydemic/"><code>epydemic</code></a> libraries. Making these work
while not sacrificing interoperability a wide range of Python versions
is quite delicate.</p>
<p class="more"><a href="../../2020/12/09/backporting-python-types/">Read more…</a></p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="../../2012/10/05/typewheel/" class="u-url">The type wheel turns again</a></h1>

        
        <div class="metadata">
            <p class="dateline"><a href="../../2012/10/05/typewheel/" rel="bookmark"><i class="fa fa-clock"></i> <time class="published dt-published" datetime="2012-10-05T08:00:23+01:00" title="2012-10-05 08:00">2012-10-05 08:00</time></a></p>

                <p class="commentline"><i class="fa fa-comment"></i>         <a href="../../2012/10/05/typewheel/#disqus_thread" data-disqus-identifier="cache/posts/2012/10/05/typewheel.html">Comments</a>


        </p>
</div>
    </header><div class="p-summary entry-summary">
    <p></p>
<p>It's slightly spooky when you're discussing a topic and evidence for (or against) your position seems to spontaneously appear. The fashion for strong <em>versus</em> weak type systems seems to change on a cycle of about a decade. It might be turning again.</p>
<!--more-->

<p>On Monday I was talking with a student who's doing a project using <a href="http://nodejs.org/" target="_blank">node.js</a>, looking at using it as the basis for doing elastic concurrent programs. It's the sort of project that could underpin some kinds of low-end cloud computing, letting designers use JavaScript end to end.</p>
<p>The discussion turned to type systems, and how Javascript's very weak view of types makes things more difficult for his project, as he will have to constantly protect against having the wrong methods called. On the other hand, it makes other things easier by letting him create proxies and other structures freely. The question is then whether strongly-typed languages are preferable to weakly-typed ones.</p>
<p>In a strongly-typed language, every denotable value has a type, the language ensures that all uses of those values are type-correct and generates a type error if not. A strongly statically-typed language does this purely at compile-time, and it's generally recognised by those who advocate these approaches that it's preferable to catch as many errors as possible as early as possible. It's also recognised that this isn't always possible (think Java class loaders), and so some run-time structures are also needed -- but these can be provided so as to catch problems as early as possible (when code is loaded). (See Dobson and Matthews. <a href="http://www.simondobson.org/softcopy/ions-ecoop-2000.ps">Ionic types</a>. In ECOOP 2000 – object-oriented programming, pages 296–312. Elisa Bertoni (ed). Volume 1850 of LNCS. Springer-Verlag. 2000.)</p>
<p>For some people, static typing feels too rigid: the compile will often prevent things that the programmer "knows" to be possible. In this case a looser type regime is often preferred. Strong dynamic typing checks at every operation to make sure that the values being manipulated are type-correct; weak dynamic typing does fewer checks, often only detecting problems very late; untyped or monotyped languages do few or no checks and will apply any operation to any piece of data at the programmer's instruction.</p>
<p>I tend to fall into the strong static typing camp -- which is slightly ironic, given that I'm currently working on <a href="http://www.threaded-interpreter.org" target="_blank">untyped extensible virtual machines</a>. Programmers' beliefs that they know better than the type-checker are often erroneous, the more so as code gets more complicated.</p>
<p>The fashion for type systems seems to follow a cycle. People are using a language with strong typing when a new kind of programming comes along, often driven by some new technology. The strong types are restrictive for this new domain (having been designed for a different world) so programmers invent or re-discover languages with dynamic typing that allow them to write the code they need to write without the difficulties of fighting a type system. In large-scale systems, programmers also like being able to evolve the data structures gradually, without having to update every user. (Doing so in the presence of strong types often doesn't work, although with care it's possible.) This leads to a widespread belief that type-checking is unnecessary, difficult, for losers, <em>etc</em>, and that dynamic languages are the only way to go.</p>
<p>Then, as programs get bigger and more complicated, problems start to emerge. Typically these revolve around different parts of the system not agreeing on the exact data representation, so everyone has to check the data they receive because the language offers no guarantees that it'll be correct. (This is the down-side of being able to evolve the representation piecemeal.)  Such checks rapidly become untenable, and so programmers start thinking about whether there are automated mechanisms to improve checking -- and re-discover strong type systems.</p>
<p>Having been discussing this in the context of Javascript, I then stumbled across <a href="http://www.typescriptlang.org" target="_blank">TypeScript</a>, a Javascript extension that allows type annotations. These aren't exactly a strong type system -- they're optional, for a start -- but definitely mark a change in the way Javascript would be used, as a system with defined type structure rather than as a type free-for-all. Since Javascript occurs in a lot of systems these days -- on the front-ends, but also increasingly server-side -- this is a welcome departure. I find it hard to believe that large, long-lived component-based systems can be built in a dependable fashion using only a dynamic approach to typing. It relies too much on programmers' willingness and ability to check <em>everything</em>, <em>every time</em>.</p>
<p>Actually there <em>are</em> strong arguments for the need for non-static run-time checks, most notably in distributed systems when you can't be sure the data you receive will be type-correct even if the compiler that generated the code thinks it is, since you generally don't have complete control over all the components and their evolutions. But this isn't an argument against strong typing in general: it still helps, even if there are small holes. Instead one perhaps needs to check types at the component boundaries so that, once admitted, you have confidence in their type-correctness. This in turn places demands on the transport protocols to be self-describing in terms of their payloads' types, and doing so supports other constructs (like type-driven computation) for free without sacrificing the benefits of the strong checks. Having some dynamism (and room for run-time failure) within a generally static seems like a decent compromise.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="../../2012/08/08/forth-32-years/" class="u-url">Forth, 2^5 years ago</a></h1>

        
        <div class="metadata">
            <p class="dateline"><a href="../../2012/08/08/forth-32-years/" rel="bookmark"><i class="fa fa-clock"></i> <time class="published dt-published" datetime="2012-08-08T17:39:51+01:00" title="2012-08-08 17:39">2012-08-08 17:39</time></a></p>

                <p class="commentline"><i class="fa fa-comment"></i>         <a href="../../2012/08/08/forth-32-years/#disqus_thread" data-disqus-identifier="cache/posts/2012/08/08/forth-32-years.html">Comments</a>


        </p>
</div>
    </header><div class="p-summary entry-summary">
    <p></p>
<p>2^5 years ago this month, <em>Byte</em> magazine devoted an issue to the Forth language.</p>
<!--more-->

<p>Byte ("the small systems journal") volume 5 number 8, August 1980, was largely devoted to Forth. I only discovered this by accident, researching some background for a paper I'm writing on extensible virtual machines. What's even more remarkable is that you can <a href="http://malus.exotica.org.uk/~buzz/byte/pdf/" target="_blank">download the issue -- along with a lot of others -- as a PDF</a>.</p>
<p>That the premier hobbyist/hacker magazine of its day would give over most of an entire issue to one language tells you something about the way people thought about programming their machines back then. There was a premium on compactness: one of the first adverts in this issue of Byte is for a Cromenco Z-2H with 64Kb of RAM and 11Mb of hard disc, and proudly claiming that it  "is under $10K".</p>
<p>One article is a history of Forth, one is a tutorial, and two are deeply technical programming pieces aimed at people comfortable with the idea of writing their own software pretty much from scratch  -- and indeed, keen to get on with it. What's more, they could write software as good or better as that which they could buy (to the extent that there <em>was</em> any hobbyist software to buy). That's not something we've been able to say for at least the last 2^4 years: hobbyist software hasn't competed with commercial offerings in most domains for a long time.</p>
<p>I think there were a number of things going on. The simplicity of the machines was obviously a bonus: one could understand the hardware and software of a personal computer in its entirety, and contemplate re-writing it from the ground up as an individual or small group.</p>
<p>Expectations were lower, but that works both ways: low expectations coupled with low-performance hardware can still lead to some impressive software. But it's certainly the case that one of the main barriers to software development from-the-ground-up these days is the need to interface with so many devices and processes in order to do anything of interest: any new system would need to talk to flash drives and the web, which probably means writing device drivers and a filing system. You can get round this using hardware packages, of course: Zigbee radios have simple programmer interfaces and encapsulate the software stack inside them.</p>
<p>Another factor, though, was a difference in ambition. A hobbyist in the 1980's only had herself and her friends to impress (and be impressed by): the horizon was closer. I'm sure that led to a lot of re-definition and duplication that the internet would allow one to avoid somewhat, but in some senses it provided a better learning environment in which a sequence of problems needed solution from a programmer's own creativity and resources. That's a significantly different skill set than what's required today, where we place a value on compliance, compatibility and re-use at least as high as we place on creativity and innovation.</p>
<p>I'm not advocating a return to the past -- although programming in Forth for sensor networks does give me a tremendous sense of pleasure that I haven't felt in programming for a long time, at least partially derived from the old-school nature of it all. However, I <em>would</em> say that there's also value in this old-school style even today. The hackers who read Byte wouldn't settle for sub-standard tools: they wouldn't think twice about re-coding their compilers and operating systems (as well as their applications) if they were sub-standard. That power brings on a <em>sense</em> of power -- the ability to change what's perceived to be wrong in something-- that's to be celebrated and encouraged even today, amongst programmers who sometimes seem to be constrained by their toolchains rather than freed by them.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="../../2012/06/14/russian-dolls/" class="u-url">Layered abstractions and Russian dolls</a></h1>

        
        <div class="metadata">
            <p class="dateline"><a href="../../2012/06/14/russian-dolls/" rel="bookmark"><i class="fa fa-clock"></i> <time class="published dt-published" datetime="2012-06-14T08:00:52+01:00" title="2012-06-14 08:00">2012-06-14 08:00</time></a></p>

                <p class="commentline"><i class="fa fa-comment"></i>         <a href="../../2012/06/14/russian-dolls/#disqus_thread" data-disqus-identifier="cache/posts/2012/06/14/russian-dolls.html">Comments</a>


        </p>
</div>
    </header><div class="p-summary entry-summary">
    <p></p>
<p>The layering of abstractions has served us well, but it's now generating the sorts of complexity it was designed to solve. Time for a re-think?</p>
<!--more-->
<p>Anyone who's built a large piece of software knows that much of the effort is in managing the complexity of the project: which other software a piece of code relies on, how to keep the various aspects separate, how to manage changes and upgrades, and so on. This isn't something that's got easier over time: it has for a given code size and style, as we've understood build processes and dependency management better; but the code sizes have relentlessly increased to compensate for our improved understanding; and modern practices don't make life any easier. Downloaded code, dynamic modules and classes, client-server and the like all generate their own intrinsic complexity.</p>
<p>One of the biggest sources of complexity is the use of multiple applications, especially in enterprise systems. A typical e-commerce system, for example, will make use of a web server to present pages (which themselves might contain embedded JavaScript for client-side processing), a database to track orders and inventory, a procurement system to fulfil orders, and possibly a supply-chain management system to order new inventory. That's the application. Then there'll be the operating system, a logging facility, a facilities management system, and a load of administrative tools and scripts. And the operating system may itself be virtualised and running as a guest within another, host operating system and hypervisor, which needs its own toolset. The interactions between these tools can be mind-boggling.</p>
<p>Someone once asked: who knows how to work the <a href="http://httpd.apache.org/" target="_blank">Apache web server</a>? It sounds like a simple question -- any competent web manager? the main developers? -- but the sting in the tail is that Apache is very configurable: so configurable, in fact, that it's pretty much impossible to work out what a given combination of options will do (or, conversely, what combination of options to use to achieve a given effect). The interactions are just too complicated, and the web abounds with examples where interactions between (for example) the thread pool size, the operating system block size, and the Java virtual machine parameters conspire to crash a system that looks like it should be working fine. If you can't work one server properly -- one component of the system -- what hope is there to get a complete system humming along?</p>
<p><a href="http://blogs.cs.st-andrews.ac.uk/al/" target="_blank">Al Dearle</a> and I have been talking about this for a while. The basic issue seems to be an interaction between decomposition and dependency. In other words, the complexity comes at the "seams" between the various sub-systems, and is magnified the more configurable the components on either side of the seam are. This is important, because systems are becoming more finely decomposed: the move to component software, software-as-a-service and the like all increase the number of seams. Al's image of this is that modern systems are like Russian dolls, where each supposedly independent component contains more components that influence the size and complexity of the component containing them. You can only simplify any individual piece so far, because it depends on so many other pieces.</p>
<p>Actually a lot of the seams are now unnecessary anyway. Going back to the e-commerce example, the operating system goes to great pains to provide a process abstraction to keep the components separate -- to stop faults in the database affecting the web server, for example. Historically this made perfect sense and prevented a single faulty process in a time-sharing system affecting the processes of other users. Nowadays, however, it makes considerably less sense, for a number of reasons. Firstly, all the components are owned by a single nominal user (although there are still good reasons for separating the root user from the application user), so the security concerns are less pronounced. Secondly, all the components depend on each other, so a crash in the database will effectively terminate the web server anyway. (We're simplifying, but you get the idea.) Finally, there's a good chance that the web server, database and so on are each running in their own virtual machine, so there's only one "real" process per machine (plus all the supporting processes). The operating system is offering protection that isn't needed, because it's being provided (again) by the hypervisor running the virtual machines and perhaps (<em>again</em>) by the host operating system(s) involved.</p>
<p>We also tend to build very flexible components (like Apache), which can deal with multiple simultaneous connections, keep users separate, allow modules to be loaded and unloaded dynamically -- behave like small operating systems, in other words, replicating the OS functionality again at application level. This is despite the fact that, in enterprise configurations, you'll probably know in advance the modules to be loaded and have a single user (or small user population) and fixed set of interactions: the flexibility makes the component more complex for no net gain during operation. Although it might simplify configuration and evolution slightly, there are often other mechanisms for this: in a cloud environment one can spin-up a replacement system in an evolved state and then swap the set of VMs over cleanly.</p>
<p>It's easy to think that this makes no difference for modern machines, but that's probably not the case. All these layers still need to be resourced; more importantly, they still need to be managed, maintained and secured, which take time to do well -- with a result that they typically get done badly (if at all).</p>
<p>Can we do anything about it? One thought is that the decomposition that makes thinking about systems and programming easier makes executing those systems more complex and fragile. In many cases, once the system is configured appropriately, flexibility becomes an enemy: it'll often be too complicated to re-configure or optimise in a live environment anyway. There may be a reason to have Russian dolls when <em>designing</em> a system, but once designed it's better to make each doll solid to remove the possibility of then opening-up and falling apart.</p>
<p>So it's not decomposition that's the issue, it's <em>decomposition manifested at run-time</em>. When we add new abstractions to systems, we typically add them in the form of components or libraries that can be called from other components. These components are often general, with lots of parameters and working with multiple clients -- sound familiar? This is all good for the component-writer, as it lets the same code be re-used: but it bloats each system that uses the component, adding complexity and interactions.</p>
<p>So one thought for tackling complexity is to change where decomposition manifests itself. If instead of placing new functions in the run-time system, we placed it into the compiler used to build the run-time, we could use compilation techniques to optimise-out the unnecessary functionality so that what results is optimised for the configuration that it's actually being placed in, rather than being general enough to represent any configuration. There's substantial work on these ideas in the fields of staged compilation and partial evaluation (for example <a href="http://www.metaocaml.org/" target="_blank">MetaOCaml</a>, <a href="http://www.haskell.org/haskellwiki/Template_Haskell" target="_blank">Template Haskell</a>, Flask and the like): the flexibility is manifested at compile-time as compile-time abstractions, that in the course of compilation are removed and replaced with inflexible -- but more efficient and potentially more dependable -- specialised code. Think taking the source code for Linux, Apache and MySQL, accelerating them together at high speed, and getting out a single program that'd run on a bare machine, had nothing it didn't actually need, and had all the options for the various (conceptual) sub-systems set correctly to work together.</p>
<p>Don't believe it's possible? Neither do I. There's too much code and especially too much legacy code for this to work at enterprise (or even desktop) level. However, for embedded systems and sensor networks it's a different story. For these systems, every extra abstraction that makes the programmer's life easier is a menace if it increases the code size hitting the metal: there just isn't the memory. But there also isn't the legacy code base, and there is a crying need for better abstractions. So an approach to the Russian dolls that moves the abstractions out of the run-time and<a href="../../2011/05/evolving/" target="_blank"> into the languages and compilers</a> might work, and might considerably improve the robustness and ease of use for many systems we need to develop. It also works well with modern language technology, and with other trends like <a href="../../2011/12/middleware-doughnut/" target="_blank">ever-more-specialised middleware</a> that remove bloat and overhead at the cost of generality. Keeping the former <em>and</em> the latter seems like a worthwhile goal.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="../../2012/05/04/postmodernism-programming/" class="u-url">The post-modernisation of programming languages</a></h1>

        
        <div class="metadata">
            <p class="dateline"><a href="../../2012/05/04/postmodernism-programming/" rel="bookmark"><i class="fa fa-clock"></i> <time class="published dt-published" datetime="2012-05-04T13:17:13+01:00" title="2012-05-04 13:17">2012-05-04 13:17</time></a></p>

                <p class="commentline"><i class="fa fa-comment"></i>         <a href="../../2012/05/04/postmodernism-programming/#disqus_thread" data-disqus-identifier="cache/posts/2012/05/04/postmodernism-programming.html">Comments</a>


        </p>
</div>
    </header><div class="p-summary entry-summary">
    <p></p>
<p>Do we now have some post-modern programming languages?</p>
<!--more-->

<p>Programming languages change all the time. It's never been the case that one could learn just one and then use it: programming is too rich and complicated for that to be a solution for the majority of programmers. However, we seem to be seeing a change in what we think of as programming languages and how they're used to build larger software systems.</p>
<p>At the risk of gross over-simplification (and ridicule), let's divide languages into various "eras". In the beginning, the <em>early</em> languages were built around some explicit notion of the machine on which they were running. Assemblers were devoted to a single machine code. Higher-level languages like Forth abstracted away from the machine code but still exposed the guts of the machine, and in particular its data bus width and memory access mechanisms.</p>
<p>The next step in abstraction -- to <em>pre-modernism</em> -- was to provide a machine that was still recognisably a Von Neumann system but that hid the details of the underlying machine code and architecture. C and Pascal fall into this category: their operations and abstractions are still largely those of the physical machine, but at a sufficient remove to achieve portability and a usable programming model. But we still have a view of the machine's underlying limitations. <em>Modern</em> languages like Perl, Java and Haskell offer a model of computation, and especially a model of memory, that's considerably removed from the underlying machine and enormously simplifies the programmer's task, at least for "suitable" programs.</p>
<p>(Interestingly enough languages don't fall into eras in the sequence of their design or popularity. Lisp considerably pre-dates C but is definitely modern using the terminology above.)</p>
<p>What's perhaps not obvious is that all these languages share a common design philosophy. They are all based on a small set of primitive notions combined with some ways of combining those notions, to get compound abstractions that resemble their primitive underpinnings. In C we get a small number of base types, some compound structs and unions, and pointers, and most interesting compound structures one builds will contain pointers all over the place. In Java we can build classes that create and combine objects; in Haskell we get lists and higher-order functions as the basic building blocks. The point is that the basic concepts are <em>general</em>, as are the composition operators, and the larger capabilities are in some sense a <em>consequence</em> of these initial choices and characterise the programs it's easy (or hard) to write.</p>
<p>This philosophy makes perfect sense, of course, which explains why it's so widespread. Programmers have to get to grips with a small set of basic concepts and composition methods. Everything else flows from this, and the extensions to the language -- libraries and the like -- will be the same as code one could write oneself: they're time-savers, but not fundamentally different from your own code. As a consequence the basic concepts have to be well-chosen to support the range of programs people will want to write. Some will be easier to write than others -- that's what makes the choice of language more than simply a matter of fashion -- but there's an acceptance that pretty much anything is writeable.<em></em></p>
<p>However, we're now seeing languages emerge that aren't like this. Instead they're very much targeted at specific domains and problem sets. We've always had domain-specific languages (DSLs), of course, but the current crop seem to me to be rather different. They've abandoned the design philosophy of a small, basic set of abstractions and powerful composition, in favour of large basic abstractions and limited composition and extension. This significantly changes development, and the balance of power between the language designer and the programmer.</p>
<p>XSLT is the language that's brought this most to mind, and especially the transition from XSLT 1.0 to XSLT 2.0.</p>
<p>First we have to defend the notion that XSLT is a programming language. I first thought of it as just a transformation system for documents, and so it is: but it's targeted at such a general set of applications that it takes on the flavour of a DSL. It's essentially a functional language with pattern-matching and recursion, whose main data structure is the XML document. It lets one write programs that are driven by these documents: another way to look at it is that it gives executable semantics to a set of XML tags, allowing them to perform computation.</p>
<p>XSLT's design doesn't start with a small set of primitives. Instead it provides a collection of tags that can be used to perform the common document operations. If you want to number a list, for example, XSLT contains tags that support the common numbering formats: numbers, letters with brackets, and so forth. What?, you wanted something else? Well, you can <em>probably</em> do it, but it'll be indescribably hard because you'll be writing a program in a language for which full computation is an afterthought. Instead, XSLT 2.0 adds <em>new</em> numbering formats that you can select using a helpful set of tags, and this is done <em>within</em> the XSLT processor, not <em>using</em> the XSLT processor. Meaningful extension requires the intervention of the language designer.</p>
<p>This is a major philosophical change, a <em>post-modern</em> approach to language design. Don't focus on getting the core abstractions right: instead, build a system -- <em>any</em> system -- that demonstrates initial functionality, and then extend it with new features to meet new demands regardless of how they fit. There's no overarching conceptual scheme to the system. Instead it's judged purely on the functions it provides, regardless of how they fit together. (<a href="http://www.wall.org/~larry/pm.html" target="_blank">Larry Wall described Perl as post-modern</a>, but I don't think he meant quite what I'm getting at here -- although there are similarities.)</p>
<p>Post-modernism  works for three reasons. Firstly, no-one is expecting to write very large amounts of code in these systems. They're intended for <em>sub-</em>systems, not for systems themselves, and so the need for generality is limited. Secondly, there's a premium on speed of development rather than on maintenance, which in turn puts a premium on getting some result out quickly rather than on ensuring that, in the future, we can get any result out we need. The sub-systems are intended to change on a short timescale, so maintenance and extensibility is perceived to be less of an issue than agility. Thirdly, a lot of these languages target people who aren't programmers -- or at least don't think of themselves as programmers -- who are focused on something other than the code.</p>
<p>Post-modernism isn't wrong, and <a href="../../2011/12/middleware-doughnut/" target="_blank">appears in middleware too</a>. It's also important to realise the benefits: it makes it easier to put together larger systems, and increases <a href="../../2011/06/computing-experience/" target="_blank">the ambition of projects one can undertake</a> compared to having to build so much from scratch, But it may be misguided. The people who spent the 1960's writing all the COBOL code that's still running today never thought it'd still be being maintained -- and the consequences of that lead to code that's now impossible to change. Simple solutions have a tendency to grow into more complex ones -- "just one more feature and we're done" -- which can push the costs of inappropriate choices out along the project lifecycle.</p>
<p>More importantly, for researchers post-modernism is a seductive siren call that lets you step away from tackling some difficult choices. Instead of picking a small set of concepts, choose <em>any set</em> and then extend them, in <em>any way</em>, to build up your system. I think this obscures some insights one might otherwise gain from simplifying your set of concepts.</p>
<p>I think it's also worth remembering that increasing the size and number of abstractions isn't without cost: not for the computer or the compiler, but for the programmer. The more programmers have to remember, and in particular the less well the things to be remembered fit together as a conceptual whole, the harder it is to use the system to its fullest advantage. People instead stay with small sub-sets of the language or -- worse -- settle for programs producing results that aren't those they want, just to stay within their language comfort zone. This sort of simplification is a step backwards, and we need to be careful of the consequences.</p>
    </div>
    </article>
</div>
        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-4.html" rel="prev">Older posts</a>
            </li>
        </ul></nav><script>var disqus_shortname="simoninireland";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>
</div>
  </section><script src="../../assets/js/baguetteBox.min.js"></script><script src="../../assets/js/moment-with-locales.min.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(2, "YYYY-MM-DD HH:mm");
  </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
    ignoreClass: 'islink',
    captions: function(element) {
    return element.getElementsByTagName('img')[0].alt;
    }});
  </script><script src="../../assets/js/ToggleNav.js"></script>
</body>
</html>
