<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Simon Dobson (Posts about web services)</title><link>https://simondobson.org/</link><description></description><atom:link href="https://simondobson.org/categories/web-services.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2021 &lt;a href="mailto:simon.dobson@computer.org"&gt;Simon Dobson&lt;/a&gt; </copyright><lastBuildDate>Mon, 08 Mar 2021 08:30:42 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>The middleware doughnut</title><link>https://simondobson.org/blog/2011/12/16/middleware-doughnut/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Where has the "middle" of middleware gone?&lt;/p&gt;
&lt;!--more--&gt;

&lt;p&gt;This week I attended a couple of the workshops at the &lt;a href="http://2011.middleware-conference.org/" target="_blank"&gt;Middleware conference&lt;/a&gt;, the main venue for the research community working on systems integration middleware. In particular I was an invited speaker at the &lt;a href="http://2011.middleware-conference.org/fome/fome2011" target="_blank"&gt;Future of Middleware (FoME) workshop&lt;/a&gt;, which attracted a great bunch of people with views on where the field is going.&lt;/p&gt;
&lt;p&gt;Listening to all the talks, one of the things that jumped out was the diversity of concerns people were expressing. Those working at enterprise level were concerned with scaling-out systems to millions of users using cloud computing; at the other extreme were sensor networks people like me, worried about programming  low-powered sensor motes with at least a semblance of programming language support and software engineering process. That a group of people with this spread of interests can find useful things to talk about together says a lot about how broad a term middleware actually is.&lt;/p&gt;
&lt;p&gt;But if we compare this to years past, it was also clear that the concerns  asymmetrically affected the different groups. There were very few issues that really commanded broad interest. This led me to wonder: where has the "middle" gone from "middleware"?&lt;/p&gt;
&lt;p&gt;In the 1990s, middleware people (including me) were working with &lt;a href="https://en.wikipedia.org/wiki/Common_Object_Request_Broker_Architecture" target="_blank"&gt;CORBA&lt;/a&gt; and the like. These systems were intended for broad application in integrating client and server components into single systems. In CORBA's case this involved designing object-oriented domain models that could then be implemented using any chosen programming language and support interactions seamlessly, regardless of  implementation or distribution. CORBA provided (and indeed provides) a lot of supporting infrastructure, including dedicated wire protocols, a shared type system and object model, higher-level services, binding, call models and other groovy toys. It achieved enormous penetration into markets that value long-term interoperability and evolution, such as financial services. It also influenced a whole range of subsequent developments, including web services and service-oriented architectures that are, to some extent, defined by their similarity to, or differences with, CORBA. (For a discussion of these differences see Baker and Dobson. &lt;a href="https://simondobson.org/research/publications#Compare-SOA-DOA" target="_blank"&gt;Comparing service-oriented and distributed object architectures&lt;/a&gt;. LNCS 3760. 2005.)&lt;/p&gt;
&lt;p&gt;As is pretty much apparent from this, CORBA sits resolutely in the middle of middleware. It is intended to integrate disparate systems and allow them to work together, and evolve somewhat separately, while managing the complexity of the overall architecture. It tries to avoid the problem, identified by Bertrand Meyer, that large systems exhibit non-linear behaviour in which the cost of making any change to them is proportional, not to the size of the change being made, but to the size of the system being changed. It doesn't completely succeed in this, of course -- no system does -- but it provides a common centre around which to organise largely independent components.&lt;/p&gt;
&lt;p&gt;Another way of looking at CORBA is less flattering: that it was inherently compromised by conflicting, and in large part irreconcilable, goals. It was reasonably performant, but by no stretch of the imagination high-performance given the overheads of a complex and general-purpose wire format. It was reasonably portable, as long as one accepted the limits imposed by the single type system: no first-class functions or mobile code, for example. It was reasonably easy to port and to support new languages, but every new language binding did require considerable ingenuity both in terms of technical design and standardisation of interfaces.&lt;/p&gt;
&lt;p&gt;Sitting in the middle, in other words, was tricky and uncomfortable.&lt;/p&gt;
&lt;p&gt;The causes of, and justifications for, these compromises aren't hard to find: what else can one do if one is trying to support the whole range of applications? Each piece of middleware sits at a particular point in the design space, trading-off performance against generality for example, or advanced typing against making bindings awkward or impossible for some languages.&lt;/p&gt;
&lt;p&gt;And it's this generality that seemed to be missing from discussions of the future of middleware: no-one &lt;em&gt;intends&lt;/em&gt; to support this range any more. Instead we're seeing a division of the design space in which different application communities focus on one or two design dimensions that are undoubtedly the most important -- and largely forget the rest. For Twitter, for example, the main design goal is lightweight interaction at clients so that Twitter clients are easy to writ. They have no concern whatever with typing or reliability: if tweets are lost, who cares? For the web services community -- perhaps closest to the "spirit of the middle" -- the issues are extensibility and use of standards, with no concern for protocols, performance or end-point complexity. It's fairly easy to see that these design issues are simply too diverse to be spanned by a single middleware platform.&lt;/p&gt;
&lt;p&gt;I don't think this necessarily spells the death of integrating middleware -- and that's just as well, given that we still have to integrate these systems &lt;em&gt;despite&lt;/em&gt; their increasing heterogeneity. What it does do, though, is change the locus of innovation away from ever-larger, more complex and more general platforms towards more specialised platforms that can integrate as far as needed -- and no further, so as not to over-burden applications or developers. Several speakers talked about using component-based approaches to build platforms as well as applications. In our talk we discussed similar ideas, removing the &lt;em&gt;a priori&lt;/em&gt; assumptions underlying middleware platforms and focusing instead on how to optimise what hits the metal. (Dearle and Dobson. &lt;a href="https://simondobson.org/research/publications#FOME-11" target="_blank"&gt;Mission-oriented middleware for sensor-driven scientific systems&lt;/a&gt;. Journal of Internet Services and Applications. 2011.) This will give rise to a whole range of further challenges -- how do we guarantee the right features are available? How do we add (and remove) features on the fly? How do we find the features we need? --  that are radically different from those encountered for CORBA and similar systems. But the result will (hopefully) be to improve our ability to create, manage and evolve ever more sophisticated combinations of applications and  services, and make it easier to roll-out and scale-out the next generation of applications and scientific experiments.&lt;/p&gt;&lt;/div&gt;</description><category>Blog</category><category>conference</category><category>corba</category><category>fome</category><category>middleware</category><category>sensor networks</category><category>web services</category><guid>https://simondobson.org/blog/2011/12/16/middleware-doughnut/</guid><pubDate>Fri, 16 Dec 2011 11:09:49 GMT</pubDate></item><item><title>Contextual processes</title><link>https://simondobson.org/blog/2010/06/18/contextual-processes/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Context-aware systems are intended to follow and augment user-led, real-world processes. These differ somewhat from traditional workflow processes, but share some characteristics. Might the techniques used to implement business processes &lt;em&gt;via&lt;/em&gt; web service orchestration fit into the context-aware landscape too?&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;These ideas arose as a result of discussions at the &lt;a href="http://www.pmmps.org"&gt;PMMPS&lt;/a&gt; workshop at &lt;a href="https://simondobson.org/2010/05/impressions-pervasive-2010/"&gt;PERVASIVE 2010 in Helsinki&lt;/a&gt;. In particular, I was thinking about comments &lt;a href="http://aquigley.blogspot.com/2010/04/april-2009-keynote-talk-ides-for.html"&gt;Aaron Quigley made in his keynote&lt;/a&gt; about the need to build platforms and development environments if we're to avoid forever building just demos. The separation of function from process seems to be working in the web world: might it work in the pervasive world too?&lt;/p&gt;
&lt;p&gt;In building a pervasive system we need to integrate several components:
&lt;/p&gt;&lt;ol&gt;
    &lt;li&gt;A collection of &lt;em&gt;sensors&lt;/em&gt; that allow us to observe users in the real world&lt;/li&gt;
    &lt;li&gt;A &lt;em&gt;user&lt;/em&gt; or &lt;em&gt;situation model&lt;/em&gt; describing what the users are supposed to be doing, in terms of the possible observations we might make and inferences we might draw&lt;/li&gt;
    &lt;li&gt;A &lt;em&gt;context model&lt;/em&gt; that brings together sensor observations and situations, allowing us to infer the latter from a sequence of the former&lt;/li&gt;
    &lt;li&gt;Some &lt;em&gt;behaviour&lt;/em&gt; that's triggered depending on the situation we believe we're observing&lt;/li&gt;
&lt;/ol&gt;
Most current pervasive systems have quite simple versions of all these components. The number of sensors is often small -- sometimes only one or two, observing one user. The situation model is more properly an &lt;em&gt;activity model&lt;/em&gt; in that it classifies a user's immediate current activity, independently of any other activity at another time. The context model encapsulates a mapping from sensors to activities, which then manifest themselves in a activating or deactivating a single behaviour. Despite their simplicity, such systems can perform a lot of useful tasks.
&lt;p&gt;However, pervasive activities clearly live on a timeline: you leave home &lt;em&gt;and then&lt;/em&gt; walk to work &lt;em&gt;and then&lt;/em&gt; enter your office &lt;em&gt;and then&lt;/em&gt; check your email, and so forth. One can treat these activities as independent, but that might lose continuity of behaviour, when what you want to do depends on the route by which you got to a particular situation. Alternatively we could treat the timeline as a process, and track the user's progress along it, in the manner of an office workflow.&lt;/p&gt;
&lt;p&gt;Of course the problem is that users don't actually follow workflows like this -- or, rather, they tend to interleave actions, perform them in odd orders, leave bits out, drop one process and do another before picking-up the first (or not), and so on. So pervasive workflows aren't at all like "standard" office processes. They aren't discriminated from &lt;em&gt;other&lt;/em&gt; workflows (and non-workflow activities) happening simultaneously in the same space, with the same people and resources involved. In some simple systems the workflow actually is "closed", for example computer theatre (Pinhanez, Mase and Bobick. Interval scripts: a design paradigm for story-based interactive systems., Proceedings of CHI'97. 1997.) -- but in most cases its "open". So the question becomes, how do we describe "loose" workflows in which there is a sequence of activities, each one of which reinforces our confidence in later ones, but which contain noise and extraneous activities that interfere with the inferencing?&lt;/p&gt;
&lt;p&gt;There are several formalisms for describing sequences of activities. The one that underlies Pinhanez' work mentioned above is Allen algebra (Allen and Ferguson. Actions and events in interval temporal logic. Journal of Logic and Computation &lt;strong&gt;4&lt;/strong&gt;(5), pp.531--579. 1994.) which provides a notation for specifying how intervals of time relate: an interval &lt;em&gt;a&lt;/em&gt; occurs strictly before another &lt;em&gt;b&lt;/em&gt;, for example, which in turn contains wholly within it another interval &lt;em&gt;c&lt;/em&gt;. It's easy to see how such a process provides a model for how events from the world &lt;em&gt;should&lt;/em&gt; be observed: if we see that &lt;em&gt;b&lt;/em&gt; has ended, we can infer that &lt;em&gt;c&lt;/em&gt; has ended also because we know that &lt;em&gt;c&lt;/em&gt; is contained within &lt;em&gt;b&lt;/em&gt;, and so forth. We can do this if we don't -- or can't -- directly observe the end of &lt;em&gt;c&lt;/em&gt;. However, this implies that we can specify the relationships between intervals precisely. If we have multiple possible relationships the inferencing power degrades rapidly.&lt;/p&gt;
&lt;p&gt;Another way to look at things is to consider what "noise" means. In terms of the components we set out earlier, noise is the observation of events that don't relate to the process we're trying to observe. Suppose I'm trying to support a "going to work" process. If I'm walking to work and stop at a shop, for example, this doesn't interfere with my going to work -- it's "noise" in the sense of "something that happened that's non-contradictory of what we expected to see". On the other hand if, after leaving the shop, I go home again, that might be considered as "not noise", in the sense of "something that happened that contradicts the model we have of the process".&lt;em&gt;&lt;/em&gt; As well as events that support a process, we also have events that contradict it, and events that provide no information.&lt;/p&gt;
&lt;p&gt;Human-centred processes are therefore stochastic, and we need a stochastic process formalism. I'm not aware of any that really fit the bill: process algebras seem too rigid. Markov processes are probably the closest, but they're really designed to capture frequencies with which paths are taken rather than detours and the like. Moreover we need to enrich the event space so that observations support or refute hypotheses as to which process is being followed and where we are in it. This is rather richer than is normal, where events are purely confirmatory. In essence what we have is &lt;em&gt;process as hypothesis&lt;/em&gt; in which we try to confirm that this process is indeed happening, and where we are in it, using the event stream.&lt;/p&gt;
&lt;p&gt;It's notable that we can describe a process separately from the probabilities that constrain how it's likely to evolve, though. That suggests to me that we might need an approach like &lt;a href="http://en.wikipedia.org/wiki/Business_Process_Execution_Language"&gt;BPEL&lt;/a&gt;, where we separate the description of the process from the actions we take as a result, and also form the ways in which we move the process forward. In other words, we have a description of &lt;em&gt;what it means&lt;/em&gt; to go to work, expressed separately from &lt;em&gt;how&lt;/em&gt; we confirm that this is what's being observed in terms of sensors and events, and separated further from &lt;em&gt;what happens&lt;/em&gt; as a result of this process being followed. That sounds  a lot easier than it is, because some events are confirmatory and some aren't. Furthermore we may have several processes that can be supported  by observations up to a point and then diverge: going to work and going shopping are pretty similar until I go into a shop, and/or until I leave the shop and don't go to work. How do we handle this? We could enforce common-prefix behaviour, but that breaks the separation between process and action. We could insist on "undo" actions for "failed", no-longer-supported-by-the-observations processes, which severely complicates programming and might lead to interactions between different failed processes. Clearly there's something missing from our understanding of how to structure more complex, temporally elongated behaviours that'll need significant work to get right.&lt;/p&gt;&lt;/div&gt;</description><category>Blog</category><category>context</category><category>pervasive computing</category><category>programming</category><category>web services</category><guid>https://simondobson.org/blog/2010/06/18/contextual-processes/</guid><pubDate>Fri, 18 Jun 2010 05:00:53 GMT</pubDate></item></channel></rss>