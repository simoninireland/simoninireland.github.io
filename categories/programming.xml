<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Simon Dobson (Posts about programming)</title><link>https://simondobson.org/</link><description></description><atom:link href="https://simondobson.org/categories/programming.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2024 &lt;a href="mailto:simoninireland@gmail.com"&gt;Simon Dobson&lt;/a&gt; </copyright><lastBuildDate>Fri, 21 Jun 2024 10:39:24 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>C++ template macroprogramming versus Lisp macros</title><link>https://simondobson.org/2024/06/21/c%2B%2B-template-macroprogramming-versus-lisp-macros/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;div id="outline-container-org8cca84d" class="outline-2"&gt;
&lt;h2 id="org8cca84d"&gt;C++ template macroprogramming &lt;i&gt;versus&lt;/i&gt; Lisp macros&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org8cca84d"&gt;
&lt;p&gt;
Following on from &lt;a href="/2024/06/14/lisp-macros-versus-rust-macros/"&gt;Lisp macros versus Rust macros&lt;/a&gt;, I also want to
compare C++ templates to Lisp macros.
&lt;/p&gt;

&lt;p&gt;
Templates in C++ were designed as a way of generating typed versions
of classes. The template declares some type variables that can be
used as placeholders within a class declaration. When the template
is instanciated and provided with actual type names, these are
substituted for the type variables and the class is expanded. (It
used to literally happen like this, so each use generated a
completely new class. Modern compilers are smart enough to avoid the
code repetition.) A classic example is a typed singly-linked list:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;A&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;List&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;List&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;next&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
However, the template system also allows values to be used in
templates instead of (or as well as) type names. When these are
encountered they are expanded at compile-time, and may cause further
templates to be expanded. A classic example of this is to
pre-compute some factorials:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;unsigned&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;factorial&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;enum&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;factorial&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;factorial&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;enum&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
In this code the first clause defines a template that defines the
usual recursive factorial calculation. The second clause bottoms-out
this recursion by defining a specialised template that directly
provides the factorial of zero. This can then be used in code such
as:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;unsigned&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;factorial&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;enum&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;factorial&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;factorial&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;enum&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;factorial&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;endl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
5040
&lt;/pre&gt;


&lt;p&gt;
which outputs the factorial of 7 as one might expect – but with the
factorial having been computed at compile-time and inserted into the
code as a literal, so the calculation introduces no run-time calculation.
&lt;/p&gt;

&lt;p&gt;
There are some stringent limitations on the ways in which templates
can be expanded. They can't have mutable variables for a start
(that's why we needed to use the recursive factorial algorithm).
Weirdly this makes the template language a &lt;i&gt;functional programming
sub-set&lt;/i&gt; of C++. Having said that, as with Lisp macros, it allows
calculations that can be statically performed forward to be brought
forward to compile-time. This makes it useful for building read-only
tables, unrolling loops, and the like.
&lt;/p&gt;

&lt;p&gt;
It's &lt;a href="https://en.wikipedia.org/wiki/Template_metaprogramming#Benefits_and_drawbacks_of_template_metaprogramming"&gt;claimed&lt;/a&gt; that templates are now so akin to "normal" C++ that
they incur less of a readability penalty. That's a subjective
statement that may be true. But the template language &lt;i&gt;isn't&lt;/i&gt; C++.
While one &lt;i&gt;can&lt;/i&gt; write programs in it, they're &lt;i&gt;nothing like&lt;/i&gt; the C++ one
would normally write. The template language is Turing complete, but
that just means one can encode any &lt;i&gt;computation&lt;/i&gt;, not that one can
encode any &lt;i&gt;particular program&lt;/i&gt; – and most template programs will
require massive re-writing from the code one would write normally
for execution at run-time. Template macroprogramming is therefore a
non-trivial programming task to undertake.
&lt;/p&gt;

&lt;p&gt;
Again as with Rust &lt;i&gt;versus&lt;/i&gt; Lisp, C++ templates are an extension to
the language rather than a core part of it, although they're now
used quite extensively in the standard library for generic typing.
Also as with Rust, use of templates is semantically and
syntactically distinct from "normal" C++ code or syntax, and it's
this that causes the programming load.
&lt;/p&gt;

&lt;p&gt;
A Lisp macro for the factorial computation, by contrast, looks
&lt;i&gt;almost exactly&lt;/i&gt; like a normal factorial function that can access the
entire language, both when defined and when used:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;defmacro&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;factorial&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;labels&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nv"&gt;fact&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;               &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;                   &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="w"&gt;                   &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;fact&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;1-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;))))))&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="o"&gt;`,&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;fact&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;princ&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;factorial&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
5040
&lt;/pre&gt;


&lt;p&gt;
The choice of macro or function (&lt;code&gt;defmacro&lt;/code&gt; or &lt;code&gt;defun&lt;/code&gt;) has no further
&lt;i&gt;syntactic&lt;/i&gt; implications for the rest of the program, and no
restrictions on the code that can be used within the definition; we
could re-write the to use iteration, mutable variables, or any other
code, and it would simply be executed at compile-time. The whole
language is there, all the time. We can show this by taking a
factorial function written in "normal" Lisp and macro-ifying it to
be computed at compile-time:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;defun&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;fact&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;"Compute the factorial of M."&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;fact&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;1-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)))))&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;defmacro&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;factorial&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;`,&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;fact&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;princ&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;factorial&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
5040
&lt;/pre&gt;


&lt;p&gt;
More importantly, a Lisp (and indeed Rust) macro can abstract over
syntax as well as classes and values, and so allow the language to
be extended with new first-class-at-compile-time structures.
Templates are restricted to instanciating templates written with
a fixed syntax; in Lisp the syntax has to be "Lisp-like", although
that's a very light restriction; and in Rust a macro can use any
syntax that Rust can tokenise.
&lt;/p&gt;

&lt;p&gt;
While C++ templates are sometimes described as macroprogramming (or
metaprogramming), they're addressing a substantially different use
case to that addressed by Lisp or Rust macros, and doing so within a
more restricted computational and syntactic envelope.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>c++</category><category>lisp</category><category>macroprogramming</category><category>programming</category><guid>https://simondobson.org/2024/06/21/c%2B%2B-template-macroprogramming-versus-lisp-macros/</guid><pubDate>Fri, 21 Jun 2024 10:22:54 GMT</pubDate></item><item><title>Lisp macros versus Rust macros</title><link>https://simondobson.org/2024/06/14/lisp-macros-versus-rust-macros/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;div id="outline-container-orgf513c0d" class="outline-2"&gt;
&lt;h2 id="orgf513c0d"&gt;Lisp macros &lt;i&gt;versus&lt;/i&gt; Rust macros&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgf513c0d"&gt;
&lt;p&gt;
I was talking with one of my colleagues the other day about
programming languages, and we ended up comparing macros in Rust and
Lisp.
&lt;/p&gt;

&lt;p&gt;
Rust has a couple of &lt;a href="https://doc.rust-lang.org/reference/procedural-macros.html"&gt;couple of different kinds&lt;/a&gt; of macros:
&lt;b&gt;declarative&lt;/b&gt; macros that pattern-match on arguments to emit code; and
&lt;b&gt;procedural&lt;/b&gt; macros that perform more general code-to-code
transformations. Lisp has only one kind that operates from code to
code.
&lt;/p&gt;

&lt;p&gt;
Both approaches are &lt;i&gt;far&lt;/i&gt; more powerful than the macros in C and C++,
which are basically just string expanders. Indeed, one definition of
macroprogramming is that it's writing code that returns code, and
there's a reasonable argument that C's "macros" are programs that
return &lt;i&gt;strings&lt;/i&gt; and therefore aren't macros at all. But that's just
bring pedantic.
&lt;/p&gt;

&lt;p&gt;
The Rust operations seem quite awkward, at least from a Lisp
perspective. They're invoked in a way that's syntactically different
to ordinary code, so it's always possible to see in the source code
where procedural code generation is occurring. Perhaps that's not an
entirely bad thing, as it makes it obvious when compile-time
computation occurs – although one might also argue that a true
language extension or DSL should be so seamless that you don't &lt;i&gt;need&lt;/i&gt;
to see it.
&lt;/p&gt;

&lt;p&gt;
I think a more basic difference is in how Rust needs to handle
code-type arguments. A macro is a function from code to code, so it
needs to represent its code arguments in a way that the macros
(which is also code) can manipulate. Lisp's &lt;a href="https://en.wikipedia.org/wiki/Homoiconicity"&gt;homoiconicity&lt;/a&gt; makes this
trivial: code is a list, just like non-code, and can ba manipulated
as such. Rust doesn't have this, so code needs to be passed to
macros as a token stream that's been parsed from the program text.
That's a reasonable solution to the problem, but it does mean that
to write macros you need to understand how Rust is tokenised. You
also get a token stream, not an abstract syntax tree (AST), which
means that manipulating complex code is more difficult: essentially
you need to re-create as much of the AST as you need and traverse it
within the macro body. There's a standard library that does this for
Rust's own syntax, which simplifies matters somewhat but still means
that writing macros exposes the programmer to the underlying
representations. Hopefully they won't change, as that would break a
lot of macros.
&lt;/p&gt;

&lt;p&gt;
By contrast, Lisp macros only require an understanding of Lisp
itself, not of its internals, and can operate on the entire detailed
structure of the code arguments. It's a striking example of the
power of homoiconicity.
&lt;/p&gt;

&lt;p&gt;
An approach closer to that of Rust is also available, in Common Lisp
anyway, in the form of &lt;b&gt;reader macros&lt;/b&gt; that modify the Lisp reader to
allow access to the character stream as the source code is being
read. I think I've only ever encountered read macros for providing
new styles of literals, or variants of strings that benefit from
being treated slightly differently at read-time: they're an unusual
use case, anyway, and Lisp makes the more usual case of macros
manipulating Lisp code a lot simpler, without exposing the
programmer to parsing.
&lt;/p&gt;

&lt;p&gt;
I suspect the main difference between the two languages' approaches
is that macros are &lt;b&gt;additional&lt;/b&gt; to Rust but &lt;b&gt;inherent&lt;/b&gt; to Lisp. None of
the core of Rust uses macros: they're for extensions. By contrast,
even common operations like &lt;code&gt;defun&lt;/code&gt; in Lisp are actually macros that
expand to the simpler core operations. This perhaps explains the
Rust designers' decision to make macros syntactically distinct.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>lisp</category><category>macroprogramming</category><category>programming</category><category>rust</category><guid>https://simondobson.org/2024/06/14/lisp-macros-versus-rust-macros/</guid><pubDate>Fri, 14 Jun 2024 13:23:46 GMT</pubDate></item><item><title>TIL: The loudest Lisp program in the world</title><link>https://simondobson.org/2024/05/03/til-the-loudest-lisp-program-in-the-world/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;div id="outline-container-org69b2fff" class="outline-2"&gt;
&lt;h2 id="org69b2fff"&gt;TIL: The loudest Lisp program in the world&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org69b2fff"&gt;
&lt;p&gt;
Today I learned about a program that generates the sounds that help
people navigate as they exit long tunnels when an emergency such as
a fire has destroyed the visibility.
&lt;/p&gt;

&lt;p&gt;
&lt;a href="https://blog.funcall.org//lisp%20psychoacoustics/2024/05/01/worlds-loudest-lisp-program/"&gt;The World's Loudest Lisp Program to the Rescue&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;
This describes the challenges of building a software system that has
to work unmonitored once deployed, for years, as well as
withstanding a fairly rugged environment where, for example, the
installedc hardware will be periodically sprayed with a
high-pressure hose as the walls get cleaned. Overall the system is
soft real-time, but has to cope with component failure, network
partitions, consensus, and all the usual distributed systems
challenges, while be guaranteed to work when needed.
&lt;/p&gt;

&lt;p&gt;
The developers built the system in Common Lisp, which wouldn't be
the normal go-to choice for an embedded system. But their argument
was that they could better handle complex and changing requirements
by retaining a high level of abstraction, and that development was
overall far faster than using C. Modern Common Lisp compilers are so
efficient that there's no significant performance hit at deployment.
They made use of complicated components like planners (for which
Lisp is an ideal choice), and built a set of macros to wrap-up the
handling of industrial control and robust communications.
&lt;/p&gt;

&lt;p&gt;
It's a great read.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>lisp</category><category>programming</category><category>til</category><guid>https://simondobson.org/2024/05/03/til-the-loudest-lisp-program-in-the-world/</guid><pubDate>Fri, 03 May 2024 08:50:16 GMT</pubDate></item><item><title>Trying to refute some criticisms of Lisp</title><link>https://simondobson.org/2024/02/10/some-criticisms-of-lisp/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;div id="outline-container-orgdde4712" class="outline-2"&gt;
&lt;h2 id="orgdde4712"&gt;Trying to refute some criticisms of Lisp&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgdde4712"&gt;
&lt;p&gt;
I recently had a discussion with someone on Mastodon about Lisp and
its perceived (by them) deficiencies as a language. There were some
interesting points, but I felt I had to try to refute them, at least
partially.
&lt;/p&gt;

&lt;p&gt;
I should say from the start the I'm not blind to Lisp's many
inadequacies and anachronisms, merely pointing out that it has a
context like everything else.
&lt;/p&gt;

&lt;p&gt;
There seemed to be two main issues:
&lt;/p&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;Poor design decisions throughout, and especially a lack of static
typing&lt;/li&gt;
&lt;li&gt;The shadows of really early machines in &lt;code&gt;car&lt;/code&gt; and &lt;code&gt;cadr&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;
These points are tied together, but let's try to unpack them.
&lt;/p&gt;
&lt;/div&gt;

&lt;div id="outline-container-org56a728c" class="outline-3"&gt;
&lt;h3 id="org56a728c"&gt;Design&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org56a728c"&gt;
&lt;p&gt;
Let's start with design. Lisp is over half a century old. I'd argue
it was exceptionally well-designed – when it was designed. It
lacks most modern advances in types because … well, they didn't
exist, many of them arose as solutions to perceived problems in
Lisp (and Fortran), and many of those "solutions" still aren't
universally accepted, such as static typing itself.
&lt;/p&gt;

&lt;p&gt;
What we've actually learned is that many aspects of programming
lack any really universal solutions. If static typing were such an
obvious and unarguable route to efficiency and quality, all new
software would be being written in Haskell.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;


&lt;div id="outline-container-orgfd9b92c" class="outline-3"&gt;
&lt;h3 id="orgfd9b92c"&gt;Typing and features&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgfd9b92c"&gt;
&lt;p&gt;
And the lack of modern types isn't really as clear-cut as it
appears. The argument about the &lt;i&gt;lack&lt;/i&gt; of features in Lisp also
ignores the &lt;i&gt;presence&lt;/i&gt; of other features that are absent from
almost all other languages.
&lt;/p&gt;

&lt;p&gt;
Lisp's numeric types are surprisingly flexible. Indeed, Common Lisp
is still, in the 21st century, just about the only language in
which one can write modern crypto algorithms like Diffie-Hellman
key exchange without recourse to additional libraries, because it
has arbitrary-precision integer arithmetic built-in to the standard
operators. It also has rational numbers, so no loss of precision on
division either.
&lt;/p&gt;

&lt;p&gt;
The Common Lisp Object System (CLOS) is vastly more flexible than
&lt;i&gt;any&lt;/i&gt; modern object-oriented language. Sub-class methods can
specify their relationship with the methods they override, such as
being called after or just filtering the return values. Methods
themselves are multiple-dispatch and so can be selected based on
the types of their arguments as well as their target. The basic
mechanisms can be overridden or extended using a meta-object
protocol.
&lt;/p&gt;

&lt;p&gt;
Then there are macros. It's easy to underestimate these: after all,
C has macros, doesn't it? Well, yes – and no. A C macro is a
function from strings to strings that can do literal string
substitution of its arguments. A Lisp macro is a function from code
to code that can perform arbitrary computation. They're really not
the same things at all, and it's misleading that the same word is
used for both. (C++ templates are a closer analogy, but still
limited in comparison.)
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;


&lt;div id="outline-container-orgc66afe3" class="outline-3"&gt;
&lt;h3 id="orgc66afe3"&gt;The persistence of hardware 1: Stupid operation names&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgc66afe3"&gt;
&lt;p&gt;
The complaints about &lt;code&gt;car&lt;/code&gt; and &lt;code&gt;cdr&lt;/code&gt; are long established: they
were originally derived from &lt;a href="https://en.wikipedia.org/wiki/CAR_and_CDR"&gt;machine-language instructions on the
IBM 704&lt;/a&gt; that was used for the first Lisp implementations. They're
a terrible hold-over from that terrible decision … aren't they?
&lt;/p&gt;

&lt;p&gt;
Well, yes – and no. Of course they're terrible in one sense. But
&lt;code&gt;car&lt;/code&gt; and &lt;code&gt;cdr&lt;/code&gt; are basically nouns as far as Lisp programmers are
concerned. One could replace them with more modern usages like
&lt;code&gt;head&lt;/code&gt; and &lt;code&gt;tail&lt;/code&gt; (and indeed many Lisps define these using
macros).
&lt;/p&gt;

&lt;p&gt;
But it's important to remember that even "head" and "tail" are
analogies, sanctified by familiarity in the computer science
literature but still inexplicable to anyone outside. (If you doubt
that, try explaining to someone who isn't a programmer that a
shopping list has a "head" consisting of the first entry, and a
"tail" consisting of another, shorter, shopping list, is "in fact"
a recursive type, and you have to acquire each item of shopping
sequentially by working your way down the list from the head.)
&lt;code&gt;car&lt;/code&gt; and &lt;code&gt;cdr&lt;/code&gt; are artificial nouns, and &lt;code&gt;cons&lt;/code&gt; is an artificial
verb – but really no more artificial that &lt;code&gt;head&lt;/code&gt;, &lt;code&gt;tail&lt;/code&gt;, and
&lt;code&gt;append&lt;/code&gt;, their rough equivalents in other languages.
&lt;/p&gt;

&lt;p&gt;
One can argue that the persistence of &lt;code&gt;car&lt;/code&gt; and &lt;code&gt;cdr&lt;/code&gt; drives the
persistence of compounds like &lt;code&gt;caaddr&lt;/code&gt;. But those are unnecessary
and seldom used: barely anyone would mind if they were removed.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org876f83b" class="outline-3"&gt;
&lt;h3 id="org876f83b"&gt;The persistence of hardware 2: It happens a lot&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org876f83b"&gt;
&lt;p&gt;
The suggestion that Lisp has hardware holdovers that should be
removed also neglects these holdovers in other languages.
&lt;/p&gt;

&lt;p&gt;
As an example, check the definition of &lt;code&gt;std::memcpy&lt;/code&gt; in C++. It
doesn't work with overlapping memory areas. Why is that? – why is
it so fast, but so dangerous? Does it relate to underlying machine
features, such as machine code move instructions on particular
machines with particular restrictions? Doesn't this introduce the
risk of security flaws like buffer overruns?
&lt;/p&gt;

&lt;p&gt;
Languages with more abstracted machine models don't have these
issues. I struggle to think of how one could even introduce the
&lt;i&gt;concept&lt;/i&gt; of a buffer overrun into Lisp, other than by using some
external raw-memory-access library: the language itself is immune,
as far as I know.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb28ab00" class="outline-3"&gt;
&lt;h3 id="orgb28ab00"&gt;The different choices&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgb28ab00"&gt;
&lt;p&gt;
For the sake of argument, let's turn the argument around and ask:
give that early Lisps had proper macros, arbitrary-precision
integers, and so on, why did these features disappear from what we
now consider to be "the mainstream" of programming language design?
&lt;/p&gt;

&lt;p&gt;
Lisp's designers had a goal of building a powerful machine in which
to think: indeed, they intended it to eventually have its own
hardware designed specifically for it to run on. They therefore
didn't buy into the necessity of immediate performance, and as
their applications were largely symbolic AI they didn't need
numerical performance at all. They chose instead to create high-level
constructs even if these couldn't be compiled efficiently, and
explored using these to create more code as they identified more
and more abstract patterns whose details could be automated away.
(Paul Graham has &lt;a href="https://paulgraham.com/diff.html"&gt;a great essay&lt;/a&gt; on this.)
&lt;/p&gt;

&lt;p&gt;
Other language designers had other priorities. Often they needed to
do numerical simulation, and needed both performance and scale. So
they chose a different design pathway, emphasising efficient
compilation to the hardware they had available, and made the
compromises needed to get it. These have persisted, and that's why
we have languages with fixed-width integers scaled to fit into a
single machine register, and compilers that generate – but don't
directly execute – the code of programs, which limits our ability
to abstract and automate code generation without recourse to
complicated external tools.
&lt;/p&gt;

&lt;p&gt;
It's interesting to explore these choices. They're at one level
"just" historical: accidents that shaped the present. But at
another level they're still very much present in the hardware and
software landscape we inhabit. I think it's important that we
remind ourselves, continuously, that &lt;i&gt;much of that landscape is a
choice&lt;/i&gt;, not a given, and one we can question and change as we wish.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>lisp</category><category>programming</category><guid>https://simondobson.org/2024/02/10/some-criticisms-of-lisp/</guid><pubDate>Sat, 10 Feb 2024 17:07:48 GMT</pubDate></item><item><title>Locally overriding a function throughout a dynamic extent</title><link>https://simondobson.org/2024/01/22/locally-overriding-a-function-throughout-a-dynamic-extent/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;div id="outline-container-orge3e69f6" class="outline-2"&gt;
&lt;h2 id="orge3e69f6"&gt;Locally overriding a function throughout a dynamic extent&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orge3e69f6"&gt;
&lt;p&gt;
A horribly dangerous but occasionally useful Lisp technique.
&lt;/p&gt;

&lt;p&gt;
My use case is as follows. &lt;code&gt;ebib&lt;/code&gt; has a command to copy a
formatted reference to the kill ring, using
&lt;code&gt;citar-citeproc-format-reference&lt;/code&gt; to actually do the formatting.
This means it's easy to change the style of the formatted
reference. However, &lt;code&gt;citar-citeproc-format-reference&lt;/code&gt;  itself uses
&lt;code&gt;citar-render-bib&lt;/code&gt; with a plain-text formatter. This is a sensible
default, but since I'm almost always copying references into
org-more documents, it loses a lot of information: it'd be better
to use the org formatter, but there's no argument to specify it.
&lt;/p&gt;

&lt;p&gt;
Clearly the correct solution is to change
&lt;code&gt;citar-citeproc-format-reference&lt;/code&gt; to take a key or optional
argument to specify the formatter, but that involves changing
someone else's code. The hacker solution is to change the call
&lt;code&gt;(citeproc-render-bib proc 'plain)&lt;/code&gt; to &lt;code&gt;(citeproc-render-bib proc
  'org)&lt;/code&gt;, but without re-writing the entire surrounding function to
keep the change just to the case where I need it.
&lt;/p&gt;

&lt;p&gt;
One way to do this would be to define a variant
&lt;code&gt;citeproc-render-bib&lt;/code&gt; that ignores its second argument (the
formatter) and always uses &lt;code&gt;'org&lt;/code&gt; instead, and then substitute
this variant for the original – but &lt;i&gt;only&lt;/i&gt; in the dynamic extent
of a &lt;i&gt;particular&lt;/i&gt; call to &lt;code&gt;citar-citeproc-format-reference&lt;/code&gt;. In
most languages this would be impossible – but not in Emacs Lisp.
&lt;/p&gt;

&lt;p&gt;
The solution is to use &lt;code&gt;cl-letf&lt;/code&gt;, which overrides the values of
general places for the duration of its body forms and restores the
original value on exit (normal or otherwise). The important point
is that the change occurs across the &lt;i&gt;extent&lt;/i&gt; of the body – the
body and all the code called from the body – and not merely in
the &lt;i&gt;scope&lt;/i&gt; of the body, which would only affect calls made there
directly.
&lt;/p&gt;

&lt;p&gt;
For example, consider in the following:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;defun&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;defun&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;first&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;f&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Which when called gives:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;first&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;26&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
36
&lt;/pre&gt;


&lt;p&gt;
If we want to override the default value (10) that's passed to &lt;code&gt;f&lt;/code&gt;
and instead use 25, we can define a new version that ignores the
second argument and uses our preferred default, and then
temporarily override the definition of &lt;code&gt;f&lt;/code&gt; in the calling
environment. If we want to use the original in the overriding
definition we need to grab it first. This gives:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nf"&gt;origf&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;symbol-function&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;'f&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;cl-letf&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(((&lt;/span&gt;&lt;span class="nf"&gt;symbol-function&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;'f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;				    &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;funcall&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;origf&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;first&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;26&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
51
&lt;/pre&gt;


&lt;p&gt;
What's going on? The &lt;code&gt;cl-letf&lt;/code&gt; macro is like &lt;code&gt;let&lt;/code&gt; but works with
general places (as in &lt;code&gt;setf&lt;/code&gt;). It sets the places in its argument
list for the duration of its body, and then restores them on exit,
regardless of whether that exit is normal or &lt;i&gt;via&lt;/i&gt; a condition.
&lt;/p&gt;

&lt;p&gt;
The &lt;code&gt;(symbol-function 'f)&lt;/code&gt; form returns the place that stores the
function associated with symbol &lt;code&gt;f&lt;/code&gt;. We use it twice: once to
capture this function so we can use it later, and once to identify
the place where we store our new variant function. This new binding
is then used for all calls made from the body of the &lt;code&gt;cl-letf&lt;/code&gt;,
regardless of depth, so the call to &lt;code&gt;first&lt;/code&gt; makes use of our variant
definition of &lt;code&gt;f&lt;/code&gt; rather than the original – but with the original
then being used in the variant in our case!
&lt;/p&gt;

&lt;p&gt;
If we'd used &lt;code&gt;let&lt;/code&gt; or &lt;code&gt;cl-flet&lt;/code&gt; instead of &lt;code&gt;cl-letf&lt;/code&gt; we wouldn't
have got the behaviour we're looking for:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nf"&gt;origf&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;symbol-function&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;'f&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;cl-flet&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nf"&gt;f&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;	      &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;funcall&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;origf&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;first&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;26&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
36
&lt;/pre&gt;


&lt;p&gt;
Why? Because &lt;code&gt;let&lt;/code&gt; and &lt;code&gt;cl-flet&lt;/code&gt; work over the &lt;i&gt;scope&lt;/i&gt; of the body,
so only calls to &lt;code&gt;f&lt;/code&gt; directly from the body of the assignment are
affected – not calls from calls. This is a great illustration of
the difference between the closely-related concepts of (static,
lexical) scope and (dynamic, run-time) extent, incidentally.
&lt;/p&gt;

&lt;p&gt;
I did say it was horrible :-). It's basically like adding
temporary &lt;code&gt;:around&lt;/code&gt; advice, and could probably benefit from a
macro to wrap it up. It's also inconceivable that it's thread- or
co-routine-safe, although I haven't checked.
&lt;/p&gt;

&lt;p&gt;
Part of the horribleness comes from the fact that the redefinition
is made for the entire dynamic extent of the body forms, which
means &lt;i&gt;all&lt;/i&gt; instances of the overridden function will use the
overridden value. There might be more than you think! But for
well-understood code it's sometimes useful, avoiding duplicating
code to make tiny changes.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>emacs</category><category>lisp</category><category>programming</category><guid>https://simondobson.org/2024/01/22/locally-overriding-a-function-throughout-a-dynamic-extent/</guid><pubDate>Mon, 22 Jan 2024 10:34:45 GMT</pubDate></item><item><title>Backporting Python type annotations</title><link>https://simondobson.org/2020/12/09/backporting-python-types/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;div&gt;&lt;p&gt;I recently added type annotations to my
&lt;a href="https://simondobson.org/development/epyc/"&gt;&lt;code&gt;epyc&lt;/code&gt;&lt;/a&gt; and
&lt;a href="https://simondobson.org/development/epydemic/"&gt;&lt;code&gt;epydemic&lt;/code&gt;&lt;/a&gt; libraries. Making these work
while not sacrificing interoperability a wide range of Python versions
is quite delicate.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://simondobson.org/2020/12/09/backporting-python-types/"&gt;Read more…&lt;/a&gt; (5 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>epyc</category><category>epydemic</category><category>programming</category><category>python</category><guid>https://simondobson.org/2020/12/09/backporting-python-types/</guid><pubDate>Wed, 09 Dec 2020 10:45:43 GMT</pubDate></item><item><title>Where am I (in git)?</title><link>https://simondobson.org/2020/11/27/where-am-i/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;div&gt;&lt;p&gt;I recently started using &lt;code&gt;git&lt;/code&gt; and &lt;a href="https://github.com/simoninireland/"&gt;Github&lt;/a&gt;
in a more serious way than I've done in the past -- and promptly
started getting horrendously lost in the process.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://simondobson.org/2020/11/27/where-am-i/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>bash</category><category>git</category><category>linux</category><category>programming</category><guid>https://simondobson.org/2020/11/27/where-am-i/</guid><pubDate>Fri, 27 Nov 2020 11:14:08 GMT</pubDate></item><item><title>The type wheel turns again</title><link>https://simondobson.org/2012/10/05/typewheel/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;p&gt;It's slightly spooky when you're discussing a topic and evidence for (or against) your position seems to spontaneously appear. The fashion for strong &lt;em&gt;versus&lt;/em&gt; weak type systems seems to change on a cycle of about a decade. It might be turning again.

&lt;!--more--&gt;

On Monday I was talking with a student who's doing a project using &lt;a href="http://nodejs.org/" target="_blank"&gt;node.js&lt;/a&gt;, looking at using it as the basis for doing elastic concurrent programs. It's the sort of project that could underpin some kinds of low-end cloud computing, letting designers use JavaScript end to end.

The discussion turned to type systems, and how Javascript's very weak view of types makes things more difficult for his project, as he will have to constantly protect against having the wrong methods called. On the other hand, it makes other things easier by letting him create proxies and other structures freely. The question is then whether strongly-typed languages are preferable to weakly-typed ones.

In a strongly-typed language, every denotable value has a type, the language ensures that all uses of those values are type-correct and generates a type error if not. A strongly statically-typed language does this purely at compile-time, and it's generally recognised by those who advocate these approaches that it's preferable to catch as many errors as possible as early as possible. It's also recognised that this isn't always possible (think Java class loaders), and so some run-time structures are also needed -- but these can be provided so as to catch problems as early as possible (when code is loaded). (See Dobson and Matthews. &lt;a href="http://www.simondobson.org/softcopy/ions-ecoop-2000.ps"&gt;Ionic types&lt;/a&gt;. In ECOOP 2000 – object-oriented programming, pages 296–312. Elisa Bertoni (ed). Volume 1850 of LNCS. Springer-Verlag. 2000.)

For some people, static typing feels too rigid: the compile will often prevent things that the programmer "knows" to be possible. In this case a looser type regime is often preferred. Strong dynamic typing checks at every operation to make sure that the values being manipulated are type-correct; weak dynamic typing does fewer checks, often only detecting problems very late; untyped or monotyped languages do few or no checks and will apply any operation to any piece of data at the programmer's instruction.

I tend to fall into the strong static typing camp -- which is slightly ironic, given that I'm currently working on &lt;a href="http://www.threaded-interpreter.org" target="_blank"&gt;untyped extensible virtual machines&lt;/a&gt;. Programmers' beliefs that they know better than the type-checker are often erroneous, the more so as code gets more complicated.

The fashion for type systems seems to follow a cycle. People are using a language with strong typing when a new kind of programming comes along, often driven by some new technology. The strong types are restrictive for this new domain (having been designed for a different world) so programmers invent or re-discover languages with dynamic typing that allow them to write the code they need to write without the difficulties of fighting a type system. In large-scale systems, programmers also like being able to evolve the data structures gradually, without having to update every user. (Doing so in the presence of strong types often doesn't work, although with care it's possible.) This leads to a widespread belief that type-checking is unnecessary, difficult, for losers, &lt;em&gt;etc&lt;/em&gt;, and that dynamic languages are the only way to go.

Then, as programs get bigger and more complicated, problems start to emerge. Typically these revolve around different parts of the system not agreeing on the exact data representation, so everyone has to check the data they receive because the language offers no guarantees that it'll be correct. (This is the down-side of being able to evolve the representation piecemeal.)  Such checks rapidly become untenable, and so programmers start thinking about whether there are automated mechanisms to improve checking -- and re-discover strong type systems.

Having been discussing this in the context of Javascript, I then stumbled across &lt;a href="http://www.typescriptlang.org" target="_blank"&gt;TypeScript&lt;/a&gt;, a Javascript extension that allows type annotations. These aren't exactly a strong type system -- they're optional, for a start -- but definitely mark a change in the way Javascript would be used, as a system with defined type structure rather than as a type free-for-all. Since Javascript occurs in a lot of systems these days -- on the front-ends, but also increasingly server-side -- this is a welcome departure. I find it hard to believe that large, long-lived component-based systems can be built in a dependable fashion using only a dynamic approach to typing. It relies too much on programmers' willingness and ability to check &lt;em&gt;everything&lt;/em&gt;, &lt;em&gt;every time&lt;/em&gt;.

Actually there &lt;em&gt;are&lt;/em&gt; strong arguments for the need for non-static run-time checks, most notably in distributed systems when you can't be sure the data you receive will be type-correct even if the compiler that generated the code thinks it is, since you generally don't have complete control over all the components and their evolutions. But this isn't an argument against strong typing in general: it still helps, even if there are small holes. Instead one perhaps needs to check types at the component boundaries so that, once admitted, you have confidence in their type-correctness. This in turn places demands on the transport protocols to be self-describing in terms of their payloads' types, and doing so supports other constructs (like type-driven computation) for free without sacrificing the benefits of the strong checks. Having some dynamism (and room for run-time failure) within a generally static seems like a decent compromise.&lt;/p&gt;</description><category>javascript</category><category>programming</category><category>type systems</category><guid>https://simondobson.org/2012/10/05/typewheel/</guid><pubDate>Fri, 05 Oct 2012 07:00:23 GMT</pubDate></item><item><title>Forth, 2^5 years ago</title><link>https://simondobson.org/2012/08/08/forth-32-years/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;p&gt;2^5 years ago this month, &lt;em&gt;Byte&lt;/em&gt; magazine devoted an issue to the Forth language.

&lt;!--more--&gt;

Byte ("the small systems journal") volume 5 number 8, August 1980, was largely devoted to Forth. I only discovered this by accident, researching some background for a paper I'm writing on extensible virtual machines. What's even more remarkable is that you can &lt;a href="http://malus.exotica.org.uk/~buzz/byte/pdf/" target="_blank"&gt;download the issue -- along with a lot of others -- as a PDF&lt;/a&gt;.

That the premier hobbyist/hacker magazine of its day would give over most of an entire issue to one language tells you something about the way people thought about programming their machines back then. There was a premium on compactness: one of the first adverts in this issue of Byte is for a Cromenco Z-2H with 64Kb of RAM and 11Mb of hard disc, and proudly claiming that it  "is under $10K".

One article is a history of Forth, one is a tutorial, and two are deeply technical programming pieces aimed at people comfortable with the idea of writing their own software pretty much from scratch  -- and indeed, keen to get on with it. What's more, they could write software as good or better as that which they could buy (to the extent that there &lt;em&gt;was&lt;/em&gt; any hobbyist software to buy). That's not something we've been able to say for at least the last 2^4 years: hobbyist software hasn't competed with commercial offerings in most domains for a long time.

I think there were a number of things going on. The simplicity of the machines was obviously a bonus: one could understand the hardware and software of a personal computer in its entirety, and contemplate re-writing it from the ground up as an individual or small group.

Expectations were lower, but that works both ways: low expectations coupled with low-performance hardware can still lead to some impressive software. But it's certainly the case that one of the main barriers to software development from-the-ground-up these days is the need to interface with so many devices and processes in order to do anything of interest: any new system would need to talk to flash drives and the web, which probably means writing device drivers and a filing system. You can get round this using hardware packages, of course: Zigbee radios have simple programmer interfaces and encapsulate the software stack inside them.

Another factor, though, was a difference in ambition. A hobbyist in the 1980's only had herself and her friends to impress (and be impressed by): the horizon was closer. I'm sure that led to a lot of re-definition and duplication that the internet would allow one to avoid somewhat, but in some senses it provided a better learning environment in which a sequence of problems needed solution from a programmer's own creativity and resources. That's a significantly different skill set than what's required today, where we place a value on compliance, compatibility and re-use at least as high as we place on creativity and innovation.

I'm not advocating a return to the past -- although programming in Forth for sensor networks does give me a tremendous sense of pleasure that I haven't felt in programming for a long time, at least partially derived from the old-school nature of it all. However, I &lt;em&gt;would&lt;/em&gt; say that there's also value in this old-school style even today. The hackers who read Byte wouldn't settle for sub-standard tools: they wouldn't think twice about re-coding their compilers and operating systems (as well as their applications) if they were sub-standard. That power brings on a &lt;em&gt;sense&lt;/em&gt; of power -- the ability to change what's perceived to be wrong in something-- that's to be celebrated and encouraged even today, amongst programmers who sometimes seem to be constrained by their toolchains rather than freed by them.&lt;/p&gt;</description><category>forth</category><category>programming</category><guid>https://simondobson.org/2012/08/08/forth-32-years/</guid><pubDate>Wed, 08 Aug 2012 16:39:51 GMT</pubDate></item><item><title>Layered abstractions and Russian dolls</title><link>https://simondobson.org/2012/06/14/russian-dolls/</link><dc:creator>Simon Dobson</dc:creator><description>&lt;p&gt;The layering of abstractions has served us well, but it's now generating the sorts of complexity it was designed to solve. Time for a re-think?

&lt;!--more--&gt;Anyone who's built a large piece of software knows that much of the effort is in managing the complexity of the project: which other software a piece of code relies on, how to keep the various aspects separate, how to manage changes and upgrades, and so on. This isn't something that's got easier over time: it has for a given code size and style, as we've understood build processes and dependency management better; but the code sizes have relentlessly increased to compensate for our improved understanding; and modern practices don't make life any easier. Downloaded code, dynamic modules and classes, client-server and the like all generate their own intrinsic complexity.

One of the biggest sources of complexity is the use of multiple applications, especially in enterprise systems. A typical e-commerce system, for example, will make use of a web server to present pages (which themselves might contain embedded JavaScript for client-side processing), a database to track orders and inventory, a procurement system to fulfil orders, and possibly a supply-chain management system to order new inventory. That's the application. Then there'll be the operating system, a logging facility, a facilities management system, and a load of administrative tools and scripts. And the operating system may itself be virtualised and running as a guest within another, host operating system and hypervisor, which needs its own toolset. The interactions between these tools can be mind-boggling.

Someone once asked: who knows how to work the &lt;a href="http://httpd.apache.org/" target="_blank"&gt;Apache web server&lt;/a&gt;? It sounds like a simple question -- any competent web manager? the main developers? -- but the sting in the tail is that Apache is very configurable: so configurable, in fact, that it's pretty much impossible to work out what a given combination of options will do (or, conversely, what combination of options to use to achieve a given effect). The interactions are just too complicated, and the web abounds with examples where interactions between (for example) the thread pool size, the operating system block size, and the Java virtual machine parameters conspire to crash a system that looks like it should be working fine. If you can't work one server properly -- one component of the system -- what hope is there to get a complete system humming along?

&lt;a href="http://blogs.cs.st-andrews.ac.uk/al/" target="_blank"&gt;Al Dearle&lt;/a&gt; and I have been talking about this for a while. The basic issue seems to be an interaction between decomposition and dependency. In other words, the complexity comes at the "seams" between the various sub-systems, and is magnified the more configurable the components on either side of the seam are. This is important, because systems are becoming more finely decomposed: the move to component software, software-as-a-service and the like all increase the number of seams. Al's image of this is that modern systems are like Russian dolls, where each supposedly independent component contains more components that influence the size and complexity of the component containing them. You can only simplify any individual piece so far, because it depends on so many other pieces.

Actually a lot of the seams are now unnecessary anyway. Going back to the e-commerce example, the operating system goes to great pains to provide a process abstraction to keep the components separate -- to stop faults in the database affecting the web server, for example. Historically this made perfect sense and prevented a single faulty process in a time-sharing system affecting the processes of other users. Nowadays, however, it makes considerably less sense, for a number of reasons. Firstly, all the components are owned by a single nominal user (although there are still good reasons for separating the root user from the application user), so the security concerns are less pronounced. Secondly, all the components depend on each other, so a crash in the database will effectively terminate the web server anyway. (We're simplifying, but you get the idea.) Finally, there's a good chance that the web server, database and so on are each running in their own virtual machine, so there's only one "real" process per machine (plus all the supporting processes). The operating system is offering protection that isn't needed, because it's being provided (again) by the hypervisor running the virtual machines and perhaps (&lt;em&gt;again&lt;/em&gt;) by the host operating system(s) involved.

We also tend to build very flexible components (like Apache), which can deal with multiple simultaneous connections, keep users separate, allow modules to be loaded and unloaded dynamically -- behave like small operating systems, in other words, replicating the OS functionality again at application level. This is despite the fact that, in enterprise configurations, you'll probably know in advance the modules to be loaded and have a single user (or small user population) and fixed set of interactions: the flexibility makes the component more complex for no net gain during operation. Although it might simplify configuration and evolution slightly, there are often other mechanisms for this: in a cloud environment one can spin-up a replacement system in an evolved state and then swap the set of VMs over cleanly.

It's easy to think that this makes no difference for modern machines, but that's probably not the case. All these layers still need to be resourced; more importantly, they still need to be managed, maintained and secured, which take time to do well -- with a result that they typically get done badly (if at all).

Can we do anything about it? One thought is that the decomposition that makes thinking about systems and programming easier makes executing those systems more complex and fragile. In many cases, once the system is configured appropriately, flexibility becomes an enemy: it'll often be too complicated to re-configure or optimise in a live environment anyway. There may be a reason to have Russian dolls when &lt;em&gt;designing&lt;/em&gt; a system, but once designed it's better to make each doll solid to remove the possibility of then opening-up and falling apart.

So it's not decomposition that's the issue, it's &lt;em&gt;decomposition manifested at run-time&lt;/em&gt;. When we add new abstractions to systems, we typically add them in the form of components or libraries that can be called from other components. These components are often general, with lots of parameters and working with multiple clients -- sound familiar? This is all good for the component-writer, as it lets the same code be re-used: but it bloats each system that uses the component, adding complexity and interactions.

So one thought for tackling complexity is to change where decomposition manifests itself. If instead of placing new functions in the run-time system, we placed it into the compiler used to build the run-time, we could use compilation techniques to optimise-out the unnecessary functionality so that what results is optimised for the configuration that it's actually being placed in, rather than being general enough to represent any configuration. There's substantial work on these ideas in the fields of staged compilation and partial evaluation (for example &lt;a href="http://www.metaocaml.org/" target="_blank"&gt;MetaOCaml&lt;/a&gt;, &lt;a href="http://www.haskell.org/haskellwiki/Template_Haskell" target="_blank"&gt;Template Haskell&lt;/a&gt;, Flask and the like): the flexibility is manifested at compile-time as compile-time abstractions, that in the course of compilation are removed and replaced with inflexible -- but more efficient and potentially more dependable -- specialised code. Think taking the source code for Linux, Apache and MySQL, accelerating them together at high speed, and getting out a single program that'd run on a bare machine, had nothing it didn't actually need, and had all the options for the various (conceptual) sub-systems set correctly to work together.

Don't believe it's possible? Neither do I. There's too much code and especially too much legacy code for this to work at enterprise (or even desktop) level. However, for embedded systems and sensor networks it's a different story. For these systems, every extra abstraction that makes the programmer's life easier is a menace if it increases the code size hitting the metal: there just isn't the memory. But there also isn't the legacy code base, and there is a crying need for better abstractions. So an approach to the Russian dolls that moves the abstractions out of the run-time and&lt;a href="https://simondobson.org/2011/05/evolving/" target="_blank"&gt; into the languages and compilers&lt;/a&gt; might work, and might considerably improve the robustness and ease of use for many systems we need to develop. It also works well with modern language technology, and with other trends like &lt;a href="https://simondobson.org/2011/12/middleware-doughnut/" target="_blank"&gt;ever-more-specialised middleware&lt;/a&gt; that remove bloat and overhead at the cost of generality. Keeping the former &lt;em&gt;and&lt;/em&gt; the latter seems like a worthwhile goal.&lt;/p&gt;</description><category>compilers</category><category>programming</category><category>software engineering</category><category>virtualisation</category><guid>https://simondobson.org/2012/06/14/russian-dolls/</guid><pubDate>Thu, 14 Jun 2012 07:00:52 GMT</pubDate></item></channel></rss>