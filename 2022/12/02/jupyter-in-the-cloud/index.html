<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Notes on using Jupyter in the cloud | Simon Dobson</title>
<style>
	@font-face {
	    font-family: "libretto-icons";
	    src:url(../../../../assets/fonts/libretto-icons.eot);
	    src:url(../../../../assets/fonts/libretto-icons.eot#iefix) format("embedded-opentype"),
	    url(../../../../assets/fonts/libretto-icons.woff) format("woff"),
	    url(../../../../assets/fonts/libretto-icons.ttf) format("truetype"),
	    url(../../../../assets/fonts/libretto-icons.svg#libretto-icons) format("svg");
	    font-weight: normal;
	    font-style: normal;
	}
    </style>
<link rel="icon" href="../../../../images/favicon.png" sizes="16x16">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Sans+Mono%7CLibre+Baskerville%7CMontserrat%7CPlayfair+Display%7CTangerine">
<link rel="stylesheet" href="../../../../assets/css/libretto_styles.css">
<link rel="stylesheet" href="../../../../assets/css/baguetteBox.min.css">
<link rel="stylesheet" href="../../../../assets/css/code.css">
<link rel="stylesheet" href="../../../../assets/css/nikola_rst.css">
<link rel="stylesheet" href="../../../../assets/css/nikola_ipython.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</head>
<body>
    <!-- Navigation bar -->
    <header class="nav-bar"><div class="site-branding">
	    <h1 class="site-title">
		<a href="https://simondobson.org/" title="Simon Dobson" rel="home">Simon Dobson</a>
	    </h1>
	</div>
	<nav class="site-navigation" role="navigation"><div class="menu-toggle">
		<span class="mobile-site-title">Simon Dobson</span>
	    </div>
	    <ul class="menu">
<li><a href="../../../../index.html">Home</a></li>
		    <li><a href="../../../../personal/">About me</a></li>
		    <li><a href="../../../../research/">Research</a></li>
		    <li><a href="../../../../development/projects/">Software</a></li>
		    <li><a href="../../../../writing/">Writing</a></li>
		    <li><a href="../../../../personal/contact/">Contact</a></li>
		    <li><a href="../../../../rss.xml">RSS</a></li>
	    </ul></nav></header><!-- Page Header --><div class="title-block post-format-icon-pin">
	<div class="entry-meta">
	    <span class="posted-on">
		Posted on <a href="." rel="bookmark">Friday 2 December, 2022</a>
	    </span>
	</div>
	<h1>Notes on using Jupyter in the cloud</h1>
    </div>

	<!-- Page Content -->
    <div class="site-content" role="main">
	<article class="format-standard libretto-long-form"><div class="entry-content">
		<div id="outline-container-orgd922b0d" class="outline-2">
<h2 id="orgd922b0d">Notes on using Jupyter in the cloud</h2>
<div class="outline-text-2" id="text-orgd922b0d">
<p>
I've been thinking about running <a href="https://jupyter.org">Jupyter notebooks</a> in the cloud for
some fairly compute-intensive simulation. Specifically I want to do
epidemic and other simulations over complex networks. These are
CPU-intensive and don't make use of GPU acceleration (yet, anyway).
Using the cloud would make things easier to scale-out, especially
for those without access to a local compute cluster.
</p>

<!-- TEASER_END -->

<p>
I decided to do some experiments by writing <a href="../../../../attachments/3d/e9ecd3-991b-49e9-8419-a22be50c6b21/epydemicbasics.ipynb">a small Jupyter notebook</a>
that would exercise a cloud service by running some simulations
using <a href="https://github.com/simoninireland/epydemic">epydemic</a>, our network process simulation framework. The idea
was to see how performant the cloud services on offer are, starting
with <a href="https://colab.research.google.com/">Google Colab</a> as the most accessible.
</p>
</div>

<div id="outline-container-org31a6a9b" class="outline-3">
<h3 id="org31a6a9b">Reference execution</h3>
<div class="outline-text-3" id="text-org31a6a9b">
<p>
As a reference, I firsat ran a small experiment with an SIR
epidemic on an ER network of \(10^4\) nodes, \(\langle k \rangle =
   10\). The first experiment runs 10 repetitions sequentially on a
single core; the second runs 10 repetitions for every core we run
on. <a href="https://github.com/simoninireland/epyc">epyc</a>, our process management library, schedules worker
processes in individual processes which can then be scheduled
independently by the operating system, and which don't therefore
run into synchronisation problems due to the Python Global
Interpreter Lock.
</p>

<p>
Running this on my desktop machine (Intel Core i7@3.8GHz) on 8
cores and taking averages gives:
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
</colgroup>
<thead><tr>
<th scope="col" class="org-right">Cores</th>
<th scope="col" class="org-right">Elapsed time (s)</th>
<th scope="col" class="org-right">Mean/rep (s)</th>
<th scope="col" class="org-right">Variance</th>
</tr></thead>
<tbody>
<tr>
<td class="org-right">1</td>
<td class="org-right">38</td>
<td class="org-right">3.86</td>
<td class="org-right">0.06</td>
</tr>
<tr>
<td class="org-right">8</td>
<td class="org-right">43</td>
<td class="org-right">4.27</td>
<td class="org-right">0.09</td>
</tr>
</tbody>
</table>
<p>
There's some overhead from the collection of the experimental
results from the worker processes.
</p>
</div>
</div>

<div id="outline-container-org2e85edf" class="outline-3">
<h3 id="org2e85edf">Running epydemic on a default runtime</h3>
<div class="outline-text-3" id="text-org2e85edf">
<p>
I then tried the same experiments on the default Colab set-up.
</p>

<p>
The notebook can import libraries no problem. It can also create
HDF5 notebooks, meaning it has the underlying libraries installed
already. The GUI reports 12GB of RAM and 100GB of disc
(approximately).
</p>

<p>
We run on all the available cores, as reported by the
<code>epyc.ParallelLab.numberOfCores()</code> method. Running the same
experiments as above gives:
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
</colgroup>
<thead><tr>
<th scope="col" class="org-right">vCPUs</th>
<th scope="col" class="org-right">Elapsed time (s)</th>
<th scope="col" class="org-right">Mean/rep (s)</th>
<th scope="col" class="org-right">Variance</th>
</tr></thead>
<tbody>
<tr>
<td class="org-right">1</td>
<td class="org-right">81</td>
<td class="org-right">8.17</td>
<td class="org-right">0.90</td>
</tr>
<tr>
<td class="org-right">2</td>
<td class="org-right">100</td>
<td class="org-right">10.87</td>
<td class="org-right">0.34</td>
</tr>
</tbody>
</table>
<p>
which is a little unusual: there's definitely some overlapped
computation happening, but with large overheads and large variance.
I'm assuming that the number of <i>cores</i> reported is actually the
number of <i>hyperthreads</i>, and that they're interfering because
they're CPU-bound: <code>epyc</code> simply uses the standard Python <code>joblib</code>.
Or it might be that the underlying VM isn't really allocating cores
exclusively. There's really not enough information to decide.
</p>
</div>
</div>

<div id="outline-container-org68d40a0" class="outline-3">
<h3 id="org68d40a0">Using specific VM instances</h3>
<div class="outline-text-3" id="text-org68d40a0">
<p>
I signed up for Google Cloud's free trial, 90 days and $300 (£281)
of credit. Then set up a specific project in which to run the
experiments, and explored the different VM instance types
available.
</p>

<p>
E2 and N2 are the general-purpose instances, available in
standard or high-CPU configurations. The E2 is cheaper than the
N2 but less performant – although this only cuts in at higher
loads according to <a href="https://www.bigbitbus.com/2021/06/10/Google-Cloud-E2-N2-VMs/">this comparison</a>. Compute-optimised VMs (C2 and
C2D) are Intel Xeon or AMD EPYC Milan processors. The C2D has a
larger last-level cache and so gets recommended for HPC
workloads.
</p>

<p>
The <a href="https://cloud.google.com/compute/vm-instance-pricing">VM instance pricing</a> model charges for a single minute, and
then after the first minute charges per-second.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-right">
<col class="org-left">
<col class="org-left">
</colgroup>
<thead><tr>
<th scope="col" class="org-left">Instance</th>
<th scope="col" class="org-right">vCPUs</th>
<th scope="col" class="org-right">Memory (GB)</th>
<th scope="col" class="org-left">On-demand price/hour</th>
<th scope="col" class="org-left">Spot price/hour</th>
</tr></thead>
<tbody>
<tr>
<td class="org-left">e2-highcpu-16</td>
<td class="org-right">16</td>
<td class="org-right">16</td>
<td class="org-left">$0.395744</td>
<td class="org-left">$0.11872</td>
</tr>
<tr>
<td class="org-left">e2-highcpu-32</td>
<td class="org-right">32</td>
<td class="org-right">32</td>
<td class="org-left">$0.791488</td>
<td class="org-left">$0.23744</td>
</tr>
<tr>
<td class="org-left">n2-highcpu-64</td>
<td class="org-right">64</td>
<td class="org-right">64</td>
<td class="org-left">$2.294272</td>
<td class="org-left">$0.55552</td>
</tr>
<tr>
<td class="org-left">n2-highcpu-96</td>
<td class="org-right">96</td>
<td class="org-right">96</td>
<td class="org-left">$3.441408</td>
<td class="org-left">$0.83328</td>
</tr>
<tr>
<td class="org-left">c2-standard-60</td>
<td class="org-right">60</td>
<td class="org-right">240</td>
<td class="org-left">$3.1321</td>
<td class="org-left">$0.28428</td>
</tr>
<tr>
<td class="org-left">c2d-standard-112</td>
<td class="org-right">112</td>
<td class="org-right">448</td>
<td class="org-left">$5.0844</td>
<td class="org-left">$1.077776</td>
</tr>
</tbody>
</table>
<p>
That's quite a range of possible costs.
</p>

<p>
The <a href="https://cloud.google.com/compute/docs/instances/spot">Spot VMs</a> are cheaper, but make use of spare capacity and so
might be pre-empted (or terminated) by higher-priority jobs.
They're recommended for fault-tolerant workloads, which we could
possibly get if we extended <code>epyc</code> with some extra back-end
functions. You also can't buy them with the free tier's credits.
</p>

<p>
There is apparently a limit of 8 vCPUs when using the free tier
for some instance types in some zones. It's not abundantly clear
what the restrictions actually are.
</p>

<p>
The process to create the custom runtime is to create a Colab VM
instance from the Marketplace and associate it with an instance
type of choice, possibly choosing a zone as well. This can then
be connected to by providing the project, zone, and instance name
to the Jupyter notebook. (The project name has to be in URL form,
so lower case with dashes for spaces.) This is awkward and
requires manual copying, but once done you can acquire a
connection URL to go straight to the notebook running on that VM.
The Jupyter UI shows RAM and disc as well as the actual VM
instance it's connected to, but not the number of cores that
instance reports, which is a bit annoying.
</p>

<p>
There's also an issue in that, when you ask the machine for the
number of cores it has, it by default replies with the number of
vCPUs – which I think means hyperthreads. A 96-vCPU machine (an instance
ending in "-96") only has 48 cores, because by default 2 vCPUs
are mapped to each physical core. You can set the ratio of vCPUs
to cores (1 or 2), and the numnber of visible cores the machine
reports. So I set a ratio of 1 vCPU/core and reporting the number
of actual cores, which is the sensible choice for a compute-bound
application. Unfortunately you can't do this without stopping the
newly-created Colab VM and re-setting it's configuration: you
can't do this step at instance creation from the Marketplace. I
don't know why. (It might be possible to do it in one step from
the command line. Or create template instances with the right
configuration.) On the other hand, once it's done, it's
persistent and can be connected to using the connection URL, as
the notebook remembers the VM it's connected to.
</p>
</div>
</div>

<div id="outline-container-org3222011" class="outline-3">
<h3 id="org3222011">Experiments on specific instances</h3>
<div class="outline-text-3" id="text-org3222011">
<p>
Running the same experiments as above on different instances gives:
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
</colgroup>
<thead><tr>
<th scope="col" class="org-left">Instance</th>
<th scope="col" class="org-right">Cores</th>
<th scope="col" class="org-right">Elapsed time (s)</th>
<th scope="col" class="org-right">Mean/rep (s)</th>
<th scope="col" class="org-right">Variance</th>
</tr></thead>
<tbody>
<tr>
<td class="org-left">e2-highcpu-16</td>
<td class="org-right">1</td>
<td class="org-right">98</td>
<td class="org-right">9.81</td>
<td class="org-right">0.09</td>
</tr>
<tr>
<td class="org-left"> </td>
<td class="org-right">8</td>
<td class="org-right">96</td>
<td class="org-right">9.49</td>
<td class="org-right">0.10</td>
</tr>
<tr>
<td class="org-left">n2-standard-8</td>
<td class="org-right">1</td>
<td class="org-right">74</td>
<td class="org-right">7.44</td>
<td class="org-right">0.23</td>
</tr>
<tr>
<td class="org-left"> </td>
<td class="org-right">4</td>
<td class="org-right">69</td>
<td class="org-right">6.83</td>
<td class="org-right">0.08</td>
</tr>
<tr>
<td class="org-left">c2-standard-8</td>
<td class="org-right">1</td>
<td class="org-right">70</td>
<td class="org-right">7.05</td>
<td class="org-right">0.05</td>
</tr>
<tr>
<td class="org-left"> </td>
<td class="org-right">4</td>
<td class="org-right">66</td>
<td class="org-right">6.55</td>
<td class="org-right">0.07</td>
</tr>
</tbody>
</table>
<p>
(These are real cores, 1 vCPU/core.)
</p>

<p>
There's around a 30% speed difference between the E2 and N2
silicon, but not much at all between the N2 and C2 – despite the
latter being branded for compute-intensive workloads. Might be
that the C2's cache isn't being exploited?
</p>

<p>
We do however get the speed-up we expect from parallelism:
actually slightly more than we'd expect, since the individual
runs seem to go faster too. There's definitely some overhead
incurred in running <code>epyc</code> in parallel, so we shouldn't see
super-linear speed-up "in reality".
</p>
</div>
</div>

<div id="outline-container-org85d7107" class="outline-3">
<h3 id="org85d7107">Running larger problems</h3>
<div class="outline-text-3" id="text-org85d7107">
<p>
For more of a soak test, we can run the same SIR experiment but
using a larger ER network (\(10^5\) nodes, \(\langle k \rangle =
   10\)):
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
</colgroup>
<thead><tr>
<th scope="col" class="org-left">Instance</th>
<th scope="col" class="org-right">Cores</th>
<th scope="col" class="org-right">Elapsed time (s)</th>
<th scope="col" class="org-right">Mean/rep (s)</th>
<th scope="col" class="org-right">Variance</th>
</tr></thead>
<tbody>
<tr>
<td class="org-left">e2-highcpu-16</td>
<td class="org-right">1</td>
<td class="org-right">1235</td>
<td class="org-right">123.56</td>
<td class="org-right">1.21</td>
</tr>
<tr>
<td class="org-left"> </td>
<td class="org-right">8</td>
<td class="org-right">1216</td>
<td class="org-right">120.30</td>
<td class="org-right">0.86</td>
</tr>
<tr>
<td class="org-left">n2-standard-8</td>
<td class="org-right">1</td>
<td class="org-right">930</td>
<td class="org-right">93.09</td>
<td class="org-right">0.56</td>
</tr>
<tr>
<td class="org-left"> </td>
<td class="org-right">4</td>
<td class="org-right">869</td>
<td class="org-right">86.51</td>
<td class="org-right">1.06</td>
</tr>
<tr>
<td class="org-left">c2-standard-8</td>
<td class="org-right">1</td>
<td class="org-right">911</td>
<td class="org-right">91.18</td>
<td class="org-right">0.72</td>
</tr>
<tr>
<td class="org-left"> </td>
<td class="org-right">4</td>
<td class="org-right">849</td>
<td class="org-right">84.53</td>
<td class="org-right">0.41</td>
</tr>
</tbody>
</table>
<p>
There's that super-linear speed-up between sequential and parallel
versions again.
</p>

<p>
The performance on the standard runtime for comparison is:
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
</colgroup>
<thead><tr>
<th scope="col" class="org-right">vCPUs</th>
<th scope="col" class="org-right">Elapsed time (s)</th>
<th scope="col" class="org-right">Mean/rep (s)</th>
<th scope="col" class="org-right">Variance</th>
</tr></thead>
<tbody>
<tr>
<td class="org-right">1</td>
<td class="org-right">1070</td>
<td class="org-right">107.60</td>
<td class="org-right">3.84</td>
</tr>
<tr>
<td class="org-right">2</td>
<td class="org-right">1402</td>
<td class="org-right">140.22</td>
<td class="org-right">1.50</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-org4ee880d" class="outline-3">
<h3 id="org4ee880d">Costs</h3>
<div class="outline-text-3" id="text-org4ee880d">
<p>
Doing all the above experiments used rather less than £10 of the
budget for my free trial – although I was very careful not to
leave instances running when I wasn't actually using them. This
is an unusual thing to be considering, not part of my "normal"
work routine, and would possibly be awkward for longer-running
computations. You'd be reluctant to run something overnight if
you weren't sure it needed <i>all</i> night, for example. This might
be addressed by using the command-line tools to spin-up, execute,
and then tear-down the infrastructure using a script.
</p>
</div>
</div>

<div id="outline-container-org12b1ffd" class="outline-3">
<h3 id="org12b1ffd">Experiences: Good and not-so-good</h3>
<div class="outline-text-3" id="text-org12b1ffd">
<p>
Good:
</p>

<ul class="org-ul">
<li>Everything controlled from a web console</li>
<li>Easy to run <code>pip</code> to install dependencies</li>
<li>Once installed, the dependencies persist even if the VM is shut down</li>
<li>The GUI shows how long cells take to execute, as well as the
memory and disc of the underlying machine and its instance name</li>
<li>There's a set of command-line tools</li>
<li>Persistent links to notebooks</li>
<li>Notebook remembers its connection to the underlying VM instance</li>
</ul>
<p>
Problematic:
</p>

<ul class="org-ul">
<li>All the available instances are considerably slower than a
reasonably modern desktop workstation</li>
<li>If an application needs more than just <code>pip</code> dependencies,
that'd have to be done at the VM level using <code>ssh</code> etc</li>
<li>Fiddly sequence to get vCPU and core reporting appropriate for
HPC</li>
<li>Need to manage spin-up and tear-down of instances, and incur
costs if you forget</li>
<li>The GUI doesn't show how many cores the underlying instance has</li>
<li>The management console requires a fairly decent knowledge of
cloud computing concepts, which need to be learned somehow. I'm
not convinced the tutorials on the web site are good enough for
someone without plenty of background</li>
<li>The notebook doesn't seem to deal cleanly with disconnections,
which is a problem if you have a flaky connection</li>
</ul>
</div>
</div>
</div>
	    </div>
	</article>
</div>

	<!-- Tag Section -->
    <div class="site-content navigation-post">
	<div class="tag-head">Tags</div>
	<div class="tag-list">
		<a href="../../../../categories/cloud-computing/">cloud computing</a>
		    <span>  </span>
		<a href="../../../../categories/computational-science/">computational science</a>
		    <span>  </span>
		<a href="../../../../categories/epydemic/">epydemic</a>
		    <span>  </span>
		<a href="../../../../categories/jupyter/">jupyter</a>
		    <span>  </span>
		<a href="../../../../categories/python/">python</a>
	</div>
    </div>

	<!-- Post Navigation links -->
<nav class="site-content navigation-post" role="navigation"><div class="previous">
	    <a href="../../../11/28/me-and-my-research/" rel="prev">
		<span class="meta-nav">Older Post</span>Me and my research
	    </a>
	</div>
	<div class="next">
	    <a href="../../../../goodreads/the-storm-is-upon-us-how-qanon-became-a-movement-cult-and-conspiracy-theory-of-everything/" rel="next">
		<span class="meta-nav">Newer Post</span>The Storm Is Upon Us: How QAnon Became a Movement, Cult, and Conspiracy Theory of Everything
	    </a>
	</div>
</nav><!-- Page Footer --><section class="footer-sidebar clear" role="complementary"><div class="widget-block">
	    <aside class="widget"><h2 class="widget-title">Simon Dobson</h2>
		<div class="widget-text">Aut tace aut loquere meliora silentio</div>
	    </aside>
</div>
    </section><!-- Site Attributions --><footer class="site-footer" role="contentinfo"><div class="site-info">
	    <p></p>
	    <p>
	      Built with open-source software, especially <a href="https://emacs.org/">Emacs</a>.
	      Powered by <a href="https://getnikola.com/">Nikola</a> using a theme based on
	      <a href="https://note2self.abraham-v.com/libretto-theme-for-nikola/">Libretto</a>.
	    </p>
	    <p>
	      All content licensed under
	      <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC-BY-NC-SA-4.0</a>
	      unless otherwise noted.
	    </p>
	</div>
	<div class="social">
	    <ul class="menu"></ul>
</div>
    </footer><!-- Extra JavaScript -->
</body>
</html>
